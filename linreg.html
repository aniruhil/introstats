<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 12 Linear Regression | Data Analysis for Leadership &amp; Public Affairs:</title>
  <meta name="description" content="This is a free textbook written for students in my research methods classes." />
  <meta name="generator" content="bookdown 0.44 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 12 Linear Regression | Data Analysis for Leadership &amp; Public Affairs:" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a free textbook written for students in my research methods classes." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 12 Linear Regression | Data Analysis for Leadership &amp; Public Affairs:" />
  
  <meta name="twitter:description" content="This is a free textbook written for students in my research methods classes." />
  

<meta name="author" content="Anirudh V. S. Ruhil" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="props.html"/>
<link rel="next" href="summation.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<script src="libs/d3-4.10.2/d3.min.js"></script>
<link href="libs/collapsibleTree-0.1.6/collapsibleTree.css" rel="stylesheet" />
<script src="libs/collapsibleTree-binding-0.1.8/collapsibleTree.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.33/datatables.js"></script>
<link href="libs/dt-core-1.13.6/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.13.6/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.13.6/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.2.1/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.1/js/crosstalk.min.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
    MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
      cancel: ["Extension","cancel"],
      bcancel: ["Extension","cancel"],
      xcancel: ["Extension","cancel"],
      cancelto: ["Extension","cancel"]
    });
  });
</script>
<!-- Global Site Tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-107619033-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-107619033-2');
</script>




<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="yihui_style.css" type="text/css" />
<link rel="stylesheet" href="fontawesome.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data Analysis for Public Affairs</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#data-analysis-and-public-affairs"><i class="fa fa-check"></i><b>1.1</b> Data Analysis and Public Affairs</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#the-chapters-that-follow"><i class="fa fa-check"></i><b>1.2</b> The chapters that follow</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#keys-to-learning-data-analysis"><i class="fa fa-check"></i><b>1.3</b> Keys to Learning Data Analysis</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i><b>1.4</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction to Core Concepts</a>
<ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#statistics-versus-statistic"><i class="fa fa-check"></i><b>2.1</b> Statistics versus Statistic</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="intro.html"><a href="intro.html#parameters-versus-estimates"><i class="fa fa-check"></i><b>2.1.1</b> Parameters versus Estimates</a></li>
<li class="chapter" data-level="2.1.2" data-path="intro.html"><a href="intro.html#sampling-error-and-bias"><i class="fa fa-check"></i><b>2.1.2</b> Sampling Error and Bias</a></li>
<li class="chapter" data-level="2.1.3" data-path="intro.html"><a href="intro.html#key-elements-of-random-sampling"><i class="fa fa-check"></i><b>2.1.3</b> Key Elements of Random Sampling</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#useful-research-designs"><i class="fa fa-check"></i><b>2.2</b> Useful Research Designs</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="intro.html"><a href="intro.html#experimental"><i class="fa fa-check"></i><b>2.2.1</b> Experimental</a></li>
<li class="chapter" data-level="2.2.2" data-path="intro.html"><a href="intro.html#natural-experiments"><i class="fa fa-check"></i><b>2.2.2</b> Natural Experiments</a></li>
<li class="chapter" data-level="2.2.3" data-path="intro.html"><a href="intro.html#quasi-experiments"><i class="fa fa-check"></i><b>2.2.3</b> Quasi-Experiments</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#elements-of-a-data-set"><i class="fa fa-check"></i><b>2.3</b> Elements of a Data-set</a></li>
<li class="chapter" data-level="2.4" data-path="intro.html"><a href="intro.html#variable-types"><i class="fa fa-check"></i><b>2.4</b> Variable Types</a></li>
<li class="chapter" data-level="2.5" data-path="intro.html"><a href="intro.html#cross-sectional-time-series-and-panel-data"><i class="fa fa-check"></i><b>2.5</b> Cross-sectional, Time-Series, and Panel Data</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="intro.html"><a href="intro.html#cross-sectional-data"><i class="fa fa-check"></i><b>2.5.1</b> Cross-sectional Data</a></li>
<li class="chapter" data-level="2.5.2" data-path="intro.html"><a href="intro.html#time-series-data"><i class="fa fa-check"></i><b>2.5.2</b> Time-Series Data</a></li>
<li class="chapter" data-level="2.5.3" data-path="intro.html"><a href="intro.html#panel-data"><i class="fa fa-check"></i><b>2.5.3</b> Panel Data</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="intro.html"><a href="intro.html#levels-of-measurement"><i class="fa fa-check"></i><b>2.6</b> Levels of Measurement</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="intro.html"><a href="intro.html#nominal"><i class="fa fa-check"></i><b>2.6.1</b> Nominal</a></li>
<li class="chapter" data-level="2.6.2" data-path="intro.html"><a href="intro.html#ordinal"><i class="fa fa-check"></i><b>2.6.2</b> Ordinal</a></li>
<li class="chapter" data-level="2.6.3" data-path="intro.html"><a href="intro.html#intervalratio"><i class="fa fa-check"></i><b>2.6.3</b> Interval/Ratio</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="intro.html"><a href="intro.html#the-tricky-business-of-cause-and-effect"><i class="fa fa-check"></i><b>2.7</b> The Tricky Business of Cause-and-Effect</a></li>
<li class="chapter" data-level="2.8" data-path="intro.html"><a href="intro.html#practice-problems"><i class="fa fa-check"></i><b>2.8</b> Practice Problems</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="dataviz.html"><a href="dataviz.html"><i class="fa fa-check"></i><b>3</b> Visualizing Data</a>
<ul>
<li class="chapter" data-level="3.1" data-path="dataviz.html"><a href="dataviz.html#visualizing-nominalordinal-data"><i class="fa fa-check"></i><b>3.1</b> Visualizing Nominal/Ordinal Data</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="dataviz.html"><a href="dataviz.html#bar-charts-and-frequency-tables"><i class="fa fa-check"></i><b>3.1.1</b> Bar-charts and Frequency Tables</a></li>
<li class="chapter" data-level="3.1.2" data-path="dataviz.html"><a href="dataviz.html#contingency-tables-and-bar-charts"><i class="fa fa-check"></i><b>3.1.2</b> Contingency Tables and Bar-charts</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="dataviz.html"><a href="dataviz.html#visualizing-intervalratio-data"><i class="fa fa-check"></i><b>3.2</b> Visualizing Interval/Ratio Data</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="dataviz.html"><a href="dataviz.html#the-histogram"><i class="fa fa-check"></i><b>3.2.1</b> The Histogram</a></li>
<li class="chapter" data-level="3.2.2" data-path="dataviz.html"><a href="dataviz.html#grouped-frequency-tables"><i class="fa fa-check"></i><b>3.2.2</b> Grouped Frequency Tables</a></li>
<li class="chapter" data-level="3.2.3" data-path="dataviz.html"><a href="dataviz.html#scatterplots"><i class="fa fa-check"></i><b>3.2.3</b> Scatterplots</a></li>
<li class="chapter" data-level="3.2.4" data-path="dataviz.html"><a href="dataviz.html#line-graphs"><i class="fa fa-check"></i><b>3.2.4</b> Line Graphs</a></li>
<li class="chapter" data-level="3.2.5" data-path="dataviz.html"><a href="dataviz.html#polar-charts"><i class="fa fa-check"></i><b>3.2.5</b> Polar Charts</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="dataviz.html"><a href="dataviz.html#some-essential-rules-for-good-visualizations"><i class="fa fa-check"></i><b>3.3</b> Some Essential Rules for Good Visualizations</a></li>
<li class="chapter" data-level="3.4" data-path="dataviz.html"><a href="dataviz.html#practice-problems-1"><i class="fa fa-check"></i><b>3.4</b> Practice Problems</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="meansd.html"><a href="meansd.html"><i class="fa fa-check"></i><b>4</b> Central Tendency and Dispersion</a>
<ul>
<li class="chapter" data-level="4.1" data-path="meansd.html"><a href="meansd.html#central-tendency"><i class="fa fa-check"></i><b>4.1</b> Central Tendency</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="meansd.html"><a href="meansd.html#mean"><i class="fa fa-check"></i><b>4.1.1</b> Mean</a></li>
<li class="chapter" data-level="4.1.2" data-path="meansd.html"><a href="meansd.html#median"><i class="fa fa-check"></i><b>4.1.2</b> Median</a></li>
<li class="chapter" data-level="4.1.3" data-path="meansd.html"><a href="meansd.html#mode"><i class="fa fa-check"></i><b>4.1.3</b> Mode</a></li>
<li class="chapter" data-level="4.1.4" data-path="meansd.html"><a href="meansd.html#some-features-of-measures-of-central-tendency"><i class="fa fa-check"></i><b>4.1.4</b> Some Features of Measures of Central Tendency</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="meansd.html"><a href="meansd.html#dispersion-aka-variability"><i class="fa fa-check"></i><b>4.2</b> Dispersion (aka Variability)</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="meansd.html"><a href="meansd.html#range"><i class="fa fa-check"></i><b>4.2.1</b> Range</a></li>
<li class="chapter" data-level="4.2.2" data-path="meansd.html"><a href="meansd.html#quartiles-and-interquartile-range"><i class="fa fa-check"></i><b>4.2.2</b> Quartiles and Interquartile Range</a></li>
<li class="chapter" data-level="4.2.3" data-path="meansd.html"><a href="meansd.html#variance-and-standard-deviation"><i class="fa fa-check"></i><b>4.2.3</b> Variance and Standard Deviation</a></li>
<li class="chapter" data-level="4.2.4" data-path="meansd.html"><a href="meansd.html#why-n-1"><i class="fa fa-check"></i><b>4.2.4</b> Why <span class="math inline">\(n-1\)</span>?</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="meansd.html"><a href="meansd.html#properties-of-the-mean-and-variancestandard-deviation"><i class="fa fa-check"></i><b>4.3</b> Properties of the Mean and Variance/Standard Deviation</a></li>
<li class="chapter" data-level="4.4" data-path="meansd.html"><a href="meansd.html#the-empirical-rule"><i class="fa fa-check"></i><b>4.4</b> The Empirical Rule</a></li>
<li class="chapter" data-level="4.5" data-path="meansd.html"><a href="meansd.html#z-scores"><i class="fa fa-check"></i><b>4.5</b> Z-scores</a></li>
<li class="chapter" data-level="4.6" data-path="meansd.html"><a href="meansd.html#the-coefficient-of-variation"><i class="fa fa-check"></i><b>4.6</b> The Coefficient of Variation</a></li>
<li class="chapter" data-level="4.7" data-path="meansd.html"><a href="meansd.html#symmetric-skewed-and-bi-modal-distributions"><i class="fa fa-check"></i><b>4.7</b> Symmetric, Skewed and Bi-modal Distributions</a></li>
<li class="chapter" data-level="4.8" data-path="meansd.html"><a href="meansd.html#the-five-number-summary-and-the-box-plot"><i class="fa fa-check"></i><b>4.8</b> The Five-number Summary and the Box-plot</a></li>
<li class="chapter" data-level="4.9" data-path="meansd.html"><a href="meansd.html#the-power-of-summary-statistics-married-to-graphical-explorations"><i class="fa fa-check"></i><b>4.9</b> The Power of Summary Statistics Married to Graphical Explorations</a></li>
<li class="chapter" data-level="4.10" data-path="meansd.html"><a href="meansd.html#outliers-outliers-what-do-i-do-with-them"><i class="fa fa-check"></i><b>4.10</b> Outliers, Outliers, What do I do with them?</a></li>
<li class="chapter" data-level="4.11" data-path="meansd.html"><a href="meansd.html#beware-the-flawed-rule"><i class="fa fa-check"></i><b>4.11</b> Beware the flawed rule</a></li>
<li class="chapter" data-level="4.12" data-path="meansd.html"><a href="meansd.html#practice-problems-2"><i class="fa fa-check"></i><b>4.12</b> Practice Problems</a>
<ul>
<li class="chapter" data-level="" data-path="meansd.html"><a href="meansd.html#problem-1-2"><i class="fa fa-check"></i>Problem 1</a></li>
<li class="chapter" data-level="" data-path="meansd.html"><a href="meansd.html#problem-2-2"><i class="fa fa-check"></i>Problem 2</a></li>
<li class="chapter" data-level="" data-path="meansd.html"><a href="meansd.html#problem-3-2"><i class="fa fa-check"></i>Problem 3</a></li>
<li class="chapter" data-level="" data-path="meansd.html"><a href="meansd.html#problem-4-2"><i class="fa fa-check"></i>Problem 4</a></li>
<li class="chapter" data-level="" data-path="meansd.html"><a href="meansd.html#problem-5-2"><i class="fa fa-check"></i>Problem 5</a></li>
<li class="chapter" data-level="" data-path="meansd.html"><a href="meansd.html#problem-6-2"><i class="fa fa-check"></i>Problem 6</a></li>
<li class="chapter" data-level="" data-path="meansd.html"><a href="meansd.html#problem-7-2"><i class="fa fa-check"></i>Problem 7</a></li>
<li class="chapter" data-level="" data-path="meansd.html"><a href="meansd.html#problem-8-2"><i class="fa fa-check"></i>Problem 8</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>5</b> Probability</a>
<ul>
<li class="chapter" data-level="5.1" data-path="probability.html"><a href="probability.html#basic-concepts-and-terminology-of-probability-theory"><i class="fa fa-check"></i><b>5.1</b> Basic Concepts and Terminology of Probability Theory</a></li>
<li class="chapter" data-level="5.2" data-path="probability.html"><a href="probability.html#counting-rules-with-permutations-and-combinations"><i class="fa fa-check"></i><b>5.2</b> Counting Rules with Permutations and Combinations</a></li>
<li class="chapter" data-level="5.3" data-path="probability.html"><a href="probability.html#assigning-probabilities-to-events"><i class="fa fa-check"></i><b>5.3</b> Assigning Probabilities to Events</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="probability.html"><a href="probability.html#example-1-venture-capital-funding"><i class="fa fa-check"></i><b>5.3.1</b> Example 1: Venture Capital Funding</a></li>
<li class="chapter" data-level="5.3.2" data-path="probability.html"><a href="probability.html#example-2-powerball"><i class="fa fa-check"></i><b>5.3.2</b> Example 2: Powerball</a></li>
<li class="chapter" data-level="5.3.3" data-path="probability.html"><a href="probability.html#example-3-rolling-two-dice"><i class="fa fa-check"></i><b>5.3.3</b> Example 3: Rolling Two Dice</a></li>
<li class="chapter" data-level="5.3.4" data-path="probability.html"><a href="probability.html#example-4-fortune-500-companies"><i class="fa fa-check"></i><b>5.3.4</b> Example 4: Fortune 500 Companies</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="probability.html"><a href="probability.html#the-complement-of-an-event"><i class="fa fa-check"></i><b>5.4</b> The Complement of an Event</a></li>
<li class="chapter" data-level="5.5" data-path="probability.html"><a href="probability.html#mutually-exclusive-events"><i class="fa fa-check"></i><b>5.5</b> Mutually Exclusive Events</a></li>
<li class="chapter" data-level="5.6" data-path="probability.html"><a href="probability.html#the-addition-rule-for-mutually-exclusive-events"><i class="fa fa-check"></i><b>5.6</b> The Addition Rule for Mutually Exclusive Events</a></li>
<li class="chapter" data-level="5.7" data-path="probability.html"><a href="probability.html#addition-rule-for-non-mutually-exclusive-events"><i class="fa fa-check"></i><b>5.7</b> Addition Rule for Non-Mutually Exclusive Events</a></li>
<li class="chapter" data-level="5.8" data-path="probability.html"><a href="probability.html#independent-events-and-the-multiplication-rule"><i class="fa fa-check"></i><b>5.8</b> Independent Events and the Multiplication Rule</a></li>
<li class="chapter" data-level="5.9" data-path="probability.html"><a href="probability.html#decision-trees"><i class="fa fa-check"></i><b>5.9</b> Decision Trees</a></li>
<li class="chapter" data-level="5.10" data-path="probability.html"><a href="probability.html#conditional-probability"><i class="fa fa-check"></i><b>5.10</b> Conditional Probability</a>
<ul>
<li class="chapter" data-level="5.10.1" data-path="probability.html"><a href="probability.html#the-gender-bias-example"><i class="fa fa-check"></i><b>5.10.1</b> The Gender-bias Example</a></li>
</ul></li>
<li class="chapter" data-level="5.11" data-path="probability.html"><a href="probability.html#dependent-events"><i class="fa fa-check"></i><b>5.11</b> Dependent Events</a>
<ul>
<li class="chapter" data-level="5.11.1" data-path="probability.html"><a href="probability.html#the-monty-hall-problem"><i class="fa fa-check"></i><b>5.11.1</b> The Monty Hall Problem</a></li>
</ul></li>
<li class="chapter" data-level="5.12" data-path="probability.html"><a href="probability.html#bayes-theorem"><i class="fa fa-check"></i><b>5.12</b> Bayes’ Theorem</a>
<ul>
<li class="chapter" data-level="5.12.1" data-path="probability.html"><a href="probability.html#another-example"><i class="fa fa-check"></i><b>5.12.1</b> Another Example</a></li>
<li class="chapter" data-level="5.12.2" data-path="probability.html"><a href="probability.html#extending-bayes-rule"><i class="fa fa-check"></i><b>5.12.2</b> Extending Bayes Rule</a></li>
</ul></li>
<li class="chapter" data-level="5.13" data-path="probability.html"><a href="probability.html#key-things-to-remember"><i class="fa fa-check"></i><b>5.13</b> Key Things to Remember</a></li>
<li class="chapter" data-level="5.14" data-path="probability.html"><a href="probability.html#practice-problems-3"><i class="fa fa-check"></i><b>5.14</b> Practice Problems</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="distributions.html"><a href="distributions.html"><i class="fa fa-check"></i><b>6</b> Probability Distributions</a>
<ul>
<li class="chapter" data-level="6.1" data-path="distributions.html"><a href="distributions.html#random-variables"><i class="fa fa-check"></i><b>6.1</b> Random Variables</a></li>
<li class="chapter" data-level="6.2" data-path="distributions.html"><a href="distributions.html#probability-distributions"><i class="fa fa-check"></i><b>6.2</b> Probability Distributions</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="distributions.html"><a href="distributions.html#discrete-probability-distributions"><i class="fa fa-check"></i><b>6.2.1</b> Discrete Probability Distributions</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="distributions.html"><a href="distributions.html#continuous-probability-distributions"><i class="fa fa-check"></i><b>6.3</b> Continuous Probability Distributions</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="distributions.html"><a href="distributions.html#the-normal-distribution"><i class="fa fa-check"></i><b>6.3.1</b> The Normal Distribution</a></li>
<li class="chapter" data-level="6.3.2" data-path="distributions.html"><a href="distributions.html#the-standard-normal-distribution"><i class="fa fa-check"></i><b>6.3.2</b> The Standard Normal Distribution</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="distributions.html"><a href="distributions.html#practice-problems-4"><i class="fa fa-check"></i><b>6.4</b> Practice Problems</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="sampling.html"><a href="sampling.html"><i class="fa fa-check"></i><b>7</b> The Theory of Sampling Distributions</a>
<ul>
<li class="chapter" data-level="7.1" data-path="sampling.html"><a href="sampling.html#the-standard-error"><i class="fa fa-check"></i><b>7.1</b> The Standard Error</a></li>
<li class="chapter" data-level="7.2" data-path="sampling.html"><a href="sampling.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>7.2</b> The Central Limit Theorem</a></li>
<li class="chapter" data-level="7.3" data-path="sampling.html"><a href="sampling.html#applying-the-standard-error-and-the-central-limit-theorem"><i class="fa fa-check"></i><b>7.3</b> Applying the Standard Error and the Central Limit Theorem</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="sampling.html"><a href="sampling.html#example-1-2"><i class="fa fa-check"></i><b>7.3.1</b> Example 1</a></li>
<li class="chapter" data-level="7.3.2" data-path="sampling.html"><a href="sampling.html#example-2-2"><i class="fa fa-check"></i><b>7.3.2</b> Example 2</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="sampling.html"><a href="sampling.html#the-sampling-distribution-of-binary-proportions"><i class="fa fa-check"></i><b>7.4</b> The Sampling Distribution of Binary Proportions</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="sampling.html"><a href="sampling.html#example-1-3"><i class="fa fa-check"></i><b>7.4.1</b> Example 1</a></li>
<li class="chapter" data-level="7.4.2" data-path="sampling.html"><a href="sampling.html#example-2-3"><i class="fa fa-check"></i><b>7.4.2</b> Example 2</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="sampling.html"><a href="sampling.html#point-estimates"><i class="fa fa-check"></i><b>7.5</b> Point Estimates</a></li>
<li class="chapter" data-level="7.6" data-path="sampling.html"><a href="sampling.html#interval-estimates"><i class="fa fa-check"></i><b>7.6</b> Interval Estimates</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="sampling.html"><a href="sampling.html#example-1-4"><i class="fa fa-check"></i><b>7.6.1</b> Example 1</a></li>
<li class="chapter" data-level="7.6.2" data-path="sampling.html"><a href="sampling.html#example-2-4"><i class="fa fa-check"></i><b>7.6.2</b> Example 2</a></li>
<li class="chapter" data-level="7.6.3" data-path="sampling.html"><a href="sampling.html#interval-estimates-for-binary-proportions"><i class="fa fa-check"></i><b>7.6.3</b> Interval Estimates for Binary Proportions</a></li>
<li class="chapter" data-level="7.6.4" data-path="sampling.html"><a href="sampling.html#example-1-5"><i class="fa fa-check"></i><b>7.6.4</b> Example 1</a></li>
<li class="chapter" data-level="7.6.5" data-path="sampling.html"><a href="sampling.html#example-2-5"><i class="fa fa-check"></i><b>7.6.5</b> Example 2</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="sampling.html"><a href="sampling.html#students-t-distribution"><i class="fa fa-check"></i><b>7.7</b> Student’s t distribution</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="sampling.html"><a href="sampling.html#example-1-6"><i class="fa fa-check"></i><b>7.7.1</b> Example 1</a></li>
<li class="chapter" data-level="7.7.2" data-path="sampling.html"><a href="sampling.html#example-2-6"><i class="fa fa-check"></i><b>7.7.2</b> Example 2</a></li>
<li class="chapter" data-level="7.7.3" data-path="sampling.html"><a href="sampling.html#example-3"><i class="fa fa-check"></i><b>7.7.3</b> Example 3</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="sampling.html"><a href="sampling.html#key-concepts-to-remember"><i class="fa fa-check"></i><b>7.8</b> Key Concepts to Remember</a></li>
<li class="chapter" data-level="7.9" data-path="sampling.html"><a href="sampling.html#practice-problems-5"><i class="fa fa-check"></i><b>7.9</b> Practice Problems</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="hypothesis.html"><a href="hypothesis.html"><i class="fa fa-check"></i><b>8</b> The Logic of Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="8.1" data-path="hypothesis.html"><a href="hypothesis.html#articulating-the-hypotheses-to-be-tested"><i class="fa fa-check"></i><b>8.1</b> Articulating the Hypotheses to be tested</a></li>
<li class="chapter" data-level="8.2" data-path="hypothesis.html"><a href="hypothesis.html#type-i-and-type-ii-errors"><i class="fa fa-check"></i><b>8.2</b> Type I and Type II Errors</a></li>
<li class="chapter" data-level="8.3" data-path="hypothesis.html"><a href="hypothesis.html#the-process-of-hypothesis-testing-an-example"><i class="fa fa-check"></i><b>8.3</b> The Process of Hypothesis Testing: An Example</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="hypothesis.html"><a href="hypothesis.html#example-1-7"><i class="fa fa-check"></i><b>8.3.1</b> Example 1</a></li>
<li class="chapter" data-level="8.3.2" data-path="hypothesis.html"><a href="hypothesis.html#example-2-7"><i class="fa fa-check"></i><b>8.3.2</b> Example 2</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="hypothesis.html"><a href="hypothesis.html#confidence-intervals-for-hypothesis-tests"><i class="fa fa-check"></i><b>8.4</b> Confidence Intervals for Hypothesis Tests</a></li>
<li class="chapter" data-level="8.5" data-path="hypothesis.html"><a href="hypothesis.html#the-one-sample-t-test"><i class="fa fa-check"></i><b>8.5</b> The One-Sample t-test</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="hypothesis.html"><a href="hypothesis.html#assumptions"><i class="fa fa-check"></i><b>8.5.1</b> Assumptions</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="hypothesis.html"><a href="hypothesis.html#the-two-group-or-two-sample-t-test"><i class="fa fa-check"></i><b>8.6</b> The Two-group (or Two-sample) t-test</a>
<ul>
<li class="chapter" data-level="" data-path="hypothesis.html"><a href="hypothesis.html#assumptions-1"><i class="fa fa-check"></i>Assumptions</a></li>
<li class="chapter" data-level="8.6.1" data-path="hypothesis.html"><a href="hypothesis.html#example-1-8"><i class="fa fa-check"></i><b>8.6.1</b> Example 1</a></li>
<li class="chapter" data-level="8.6.2" data-path="hypothesis.html"><a href="hypothesis.html#example-2-8"><i class="fa fa-check"></i><b>8.6.2</b> Example 2</a></li>
<li class="chapter" data-level="8.6.3" data-path="hypothesis.html"><a href="hypothesis.html#caution"><i class="fa fa-check"></i><b>8.6.3</b> Caution</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="hypothesis.html"><a href="hypothesis.html#paired-t-tests"><i class="fa fa-check"></i><b>8.7</b> Paired t-tests</a>
<ul>
<li class="chapter" data-level="" data-path="hypothesis.html"><a href="hypothesis.html#assumptions-2"><i class="fa fa-check"></i>Assumptions</a></li>
<li class="chapter" data-level="" data-path="hypothesis.html"><a href="hypothesis.html#the-testing-protocol"><i class="fa fa-check"></i>The Testing Protocol</a></li>
<li class="chapter" data-level="8.7.1" data-path="hypothesis.html"><a href="hypothesis.html#example-1-9"><i class="fa fa-check"></i><b>8.7.1</b> Example 1</a></li>
<li class="chapter" data-level="8.7.2" data-path="hypothesis.html"><a href="hypothesis.html#example-2-9"><i class="fa fa-check"></i><b>8.7.2</b> Example 2</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="hypothesis.html"><a href="hypothesis.html#practice-problems-6"><i class="fa fa-check"></i><b>8.8</b> Practice Problems</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="anova.html"><a href="anova.html"><i class="fa fa-check"></i><b>9</b> Analysis of Variance (ANOVA)</a>
<ul>
<li class="chapter" data-level="9.1" data-path="anova.html"><a href="anova.html#the-logic-of-anova"><i class="fa fa-check"></i><b>9.1</b> The Logic of ANOVA</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="anova.html"><a href="anova.html#example-1-systolic-blood-pressure-and-treatments"><i class="fa fa-check"></i><b>9.1.1</b> Example 1: Systolic Blood Pressure and Treatments</a></li>
<li class="chapter" data-level="9.1.2" data-path="anova.html"><a href="anova.html#example-2-pre-surgical-fitness-and-recovery-times"><i class="fa fa-check"></i><b>9.1.2</b> Example 2: Pre-surgical Fitness and Recovery Times</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="anova.html"><a href="anova.html#anova-with-two-independent-variables-aka-factors"><i class="fa fa-check"></i><b>9.2</b> ANOVA with two independent variables (aka factors)</a></li>
<li class="chapter" data-level="9.3" data-path="anova.html"><a href="anova.html#interaction-effects"><i class="fa fa-check"></i><b>9.3</b> Interaction effects</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="anova.html"><a href="anova.html#example-01-the-drug-and-diet-example-modified"><i class="fa fa-check"></i><b>9.3.1</b> Example 01: The Drug and Diet Example Modified</a></li>
<li class="chapter" data-level="9.3.2" data-path="anova.html"><a href="anova.html#example-02-pedagogy-subject-and-learning"><i class="fa fa-check"></i><b>9.3.2</b> Example 02: Pedagogy, Subject, and Learning</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="chisq.html"><a href="chisq.html"><i class="fa fa-check"></i><b>10</b> Working with Multinomial Data</a>
<ul>
<li class="chapter" data-level="10.1" data-path="chisq.html"><a href="chisq.html#a-single-multinomial-variable-goodness-of-fit-test"><i class="fa fa-check"></i><b>10.1</b> A Single Multinomial Variable (Goodness-of-fit test)</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="chisq.html"><a href="chisq.html#assumptions-3"><i class="fa fa-check"></i><b>10.1.1</b> Assumptions</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="chisq.html"><a href="chisq.html#the-chi2-test-of-independenceassociation"><i class="fa fa-check"></i><b>10.2</b> The <span class="math inline">\(\chi^2\)</span> Test of Independence/Association</a></li>
<li class="chapter" data-level="10.3" data-path="chisq.html"><a href="chisq.html#fishers-exact-test"><i class="fa fa-check"></i><b>10.3</b> Fisher’s Exact Test</a></li>
<li class="chapter" data-level="10.4" data-path="chisq.html"><a href="chisq.html#a-cautionary-tale"><i class="fa fa-check"></i><b>10.4</b> A Cautionary Tale</a></li>
<li class="chapter" data-level="10.5" data-path="chisq.html"><a href="chisq.html#practice-problems-7"><i class="fa fa-check"></i><b>10.5</b> Practice Problems</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="props.html"><a href="props.html"><i class="fa fa-check"></i><b>11</b> Comparing Proportions</a>
<ul>
<li class="chapter" data-level="11.1" data-path="props.html"><a href="props.html#specifyng-hypotheses-for-one-group-tests"><i class="fa fa-check"></i><b>11.1</b> Specifyng Hypotheses for One-group Tests</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="props.html"><a href="props.html#the-normal-approximation-to-one-group-tests"><i class="fa fa-check"></i><b>11.1.1</b> The Normal Approximation to One-group Tests</a></li>
<li class="chapter" data-level="11.1.2" data-path="props.html"><a href="props.html#the-binomial-test"><i class="fa fa-check"></i><b>11.1.2</b> The Binomial Test</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="props.html"><a href="props.html#two-group-tests"><i class="fa fa-check"></i><b>11.2</b> Two-group Tests</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="props.html"><a href="props.html#example-1-12"><i class="fa fa-check"></i><b>11.2.1</b> Example 1</a></li>
<li class="chapter" data-level="11.2.2" data-path="props.html"><a href="props.html#the-chi2-test"><i class="fa fa-check"></i><b>11.2.2</b> The <span class="math inline">\(\chi^2\)</span> Test</a></li>
<li class="chapter" data-level="11.2.3" data-path="props.html"><a href="props.html#fishers-exact-test-1"><i class="fa fa-check"></i><b>11.2.3</b> Fisher’s Exact Test</a></li>
<li class="chapter" data-level="11.2.4" data-path="props.html"><a href="props.html#example-2-12"><i class="fa fa-check"></i><b>11.2.4</b> Example 2</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="props.html"><a href="props.html#measuring-the-strength-of-the-association"><i class="fa fa-check"></i><b>11.3</b> Measuring the Strength of the Association</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="props.html"><a href="props.html#goodman-kruskal-lambda-lambda"><i class="fa fa-check"></i><b>11.3.1</b> Goodman-Kruskal Lambda <span class="math inline">\((\lambda)\)</span></a></li>
<li class="chapter" data-level="11.3.2" data-path="props.html"><a href="props.html#phi-phi-coefficient"><i class="fa fa-check"></i><b>11.3.2</b> Phi <span class="math inline">\((\phi)\)</span> Coefficient</a></li>
<li class="chapter" data-level="11.3.3" data-path="props.html"><a href="props.html#cramers-v-and-contingency-c"><i class="fa fa-check"></i><b>11.3.3</b> Cramer’s <span class="math inline">\(V\)</span> and Contingency <span class="math inline">\(C\)</span></a></li>
<li class="chapter" data-level="11.3.4" data-path="props.html"><a href="props.html#goodman-kruskal-gamma-gamma"><i class="fa fa-check"></i><b>11.3.4</b> Goodman-Kruskal Gamma <span class="math inline">\((\gamma)\)</span></a></li>
<li class="chapter" data-level="11.3.5" data-path="props.html"><a href="props.html#kendalls-tau_b"><i class="fa fa-check"></i><b>11.3.5</b> Kendall’s <span class="math inline">\((\tau_b)\)</span></a></li>
<li class="chapter" data-level="11.3.6" data-path="props.html"><a href="props.html#kendalls-tau_c"><i class="fa fa-check"></i><b>11.3.6</b> Kendall’s <span class="math inline">\((\tau_c)\)</span></a></li>
<li class="chapter" data-level="11.3.7" data-path="props.html"><a href="props.html#somers-d"><i class="fa fa-check"></i><b>11.3.7</b> Somer’s <span class="math inline">\(D\)</span></a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="props.html"><a href="props.html#practice-problems-8"><i class="fa fa-check"></i><b>11.4</b> Practice Problems</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="linreg.html"><a href="linreg.html"><i class="fa fa-check"></i><b>12</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="12.1" data-path="linreg.html"><a href="linreg.html#correlations"><i class="fa fa-check"></i><b>12.1</b> Correlations</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="linreg.html"><a href="linreg.html#pearson-correlation-coefficient"><i class="fa fa-check"></i><b>12.1.1</b> Pearson Correlation Coefficient</a></li>
<li class="chapter" data-level="12.1.2" data-path="linreg.html"><a href="linreg.html#spearman-correlation-coefficient"><i class="fa fa-check"></i><b>12.1.2</b> Spearman Correlation Coefficient</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="linreg.html"><a href="linreg.html#bivariate-regression"><i class="fa fa-check"></i><b>12.2</b> Bivariate Regression</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="linreg.html"><a href="linreg.html#the-method-of-ordinary-least-squares"><i class="fa fa-check"></i><b>12.2.1</b> The Method of Ordinary Least Squares</a></li>
<li class="chapter" data-level="12.2.2" data-path="linreg.html"><a href="linreg.html#population-regression-function-vs.-sample-regression-function"><i class="fa fa-check"></i><b>12.2.2</b> Population Regression Function vs. Sample Regression Function</a></li>
<li class="chapter" data-level="12.2.3" data-path="linreg.html"><a href="linreg.html#hypotheses"><i class="fa fa-check"></i><b>12.2.3</b> Hypotheses</a></li>
<li class="chapter" data-level="12.2.4" data-path="linreg.html"><a href="linreg.html#the-r2"><i class="fa fa-check"></i><b>12.2.4</b> The <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="12.2.5" data-path="linreg.html"><a href="linreg.html#confidence-intervals-vs.-prediction-intervals"><i class="fa fa-check"></i><b>12.2.5</b> Confidence Intervals vs. Prediction Intervals</a></li>
<li class="chapter" data-level="12.2.6" data-path="linreg.html"><a href="linreg.html#dummy-variables"><i class="fa fa-check"></i><b>12.2.6</b> Dummy Variables</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="linreg.html"><a href="linreg.html#multiple-regression"><i class="fa fa-check"></i><b>12.3</b> Multiple Regression</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="linreg.html"><a href="linreg.html#two-numeric-i.e.-continuous-independent-variables"><i class="fa fa-check"></i><b>12.3.1</b> Two Numeric (i.e., Continuous) Independent Variables</a></li>
<li class="chapter" data-level="12.3.2" data-path="linreg.html"><a href="linreg.html#one-numeric-and-one-categorical-independent-variable"><i class="fa fa-check"></i><b>12.3.2</b> One Numeric and One Categorical Independent Variable</a></li>
<li class="chapter" data-level="12.3.3" data-path="linreg.html"><a href="linreg.html#interaction-effects-1"><i class="fa fa-check"></i><b>12.3.3</b> Interaction Effects</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="linreg.html"><a href="linreg.html#assumptions-of-linear-regression"><i class="fa fa-check"></i><b>12.4</b> Assumptions of Linear Regression</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="linreg.html"><a href="linreg.html#assumption-1-linear-regression-model"><i class="fa fa-check"></i><b>12.4.1</b> Assumption 1: Linear Regression Model</a></li>
<li class="chapter" data-level="12.4.2" data-path="linreg.html"><a href="linreg.html#assumption-2-x-values-fixed-in-repeated-sampling"><i class="fa fa-check"></i><b>12.4.2</b> Assumption 2: <span class="math inline">\(x\)</span> values fixed in repeated sampling</a></li>
<li class="chapter" data-level="12.4.3" data-path="linreg.html"><a href="linreg.html#assumption-3-zero-conditional-mean-value-of-residuals"><i class="fa fa-check"></i><b>12.4.3</b> Assumption 3: Zero conditional mean value of Residuals</a></li>
<li class="chapter" data-level="12.4.4" data-path="linreg.html"><a href="linreg.html#assumption-4-homoscedasticity"><i class="fa fa-check"></i><b>12.4.4</b> Assumption 4: Homoscedasticity</a></li>
<li class="chapter" data-level="12.4.5" data-path="linreg.html"><a href="linreg.html#assumption-5-no-autocorrelation"><i class="fa fa-check"></i><b>12.4.5</b> Assumption 5: No Autocorrelation</a></li>
<li class="chapter" data-level="12.4.6" data-path="linreg.html"><a href="linreg.html#assumptions-6-7-and-8"><i class="fa fa-check"></i><b>12.4.6</b> Assumptions 6, 7, and 8</a></li>
<li class="chapter" data-level="12.4.7" data-path="linreg.html"><a href="linreg.html#assumptions-9-and-10"><i class="fa fa-check"></i><b>12.4.7</b> Assumptions 9 and 10</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="linreg.html"><a href="linreg.html#practice-problems-9"><i class="fa fa-check"></i><b>12.5</b> Practice Problems</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="summation.html"><a href="summation.html"><i class="fa fa-check"></i><b>13</b> The Summation Operator</a>
<ul>
<li class="chapter" data-level="13.1" data-path="summation.html"><a href="summation.html#the-single-summation-operator"><i class="fa fa-check"></i><b>13.1</b> The Single Summation Operator</a></li>
<li class="chapter" data-level="13.2" data-path="summation.html"><a href="summation.html#the-double-subscript"><i class="fa fa-check"></i><b>13.2</b> The Double Subscript</a></li>
<li class="chapter" data-level="13.3" data-path="summation.html"><a href="summation.html#the-constant-rule"><i class="fa fa-check"></i><b>13.3</b> The Constant Rule</a></li>
<li class="chapter" data-level="13.4" data-path="summation.html"><a href="summation.html#the-distributive-rule"><i class="fa fa-check"></i><b>13.4</b> The Distributive Rule</a></li>
<li class="chapter" data-level="13.5" data-path="summation.html"><a href="summation.html#the-dot-notation"><i class="fa fa-check"></i><b>13.5</b> The Dot Notation</a></li>
<li class="chapter" data-level="13.6" data-path="summation.html"><a href="summation.html#the-basic-rules-of-summation"><i class="fa fa-check"></i><b>13.6</b> The Basic Rules of Summation</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Analysis for Leadership &amp; Public Affairs:</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="linreg" class="section level1 hasAnchor" number="12">
<h1><span class="header-section-number">Chapter 12</span> Linear Regression<a href="linreg.html#linreg" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In this chapter we close the book with an introduction to <code>regression models</code> – the cornerstone of almost all statistical techniques you see being used in this age of “big data”, “health analytics” and “predictive modeling”. The goal of regression models is to help us understand what variables have a statistically significant impact on some outcome of interest, and how well the regression model we have built can predict outcomes in the future. Imagine, if you will, that you could understand and predict <a href="http://www.nhc.noaa.gov/outreach/history/">major hurricanes that have hit the United States</a>. If you could accomplish this predictive feat, why then we would know when a hurricane will hit and where, the path it will take, likely damage, the recovery costs, and more. Or perhaps it is a question of delivering better health care and if we can now predict how a patient will respond to total hip or knee surgery, what factors help or hinder speedier recovery, and so on, then patients’ lives will be improved even as health care delivery costs plummet. Indeed, regression models have been used for well over a century now and are employed daily in academia and in the real-world.</p>
<div id="correlations" class="section level2 hasAnchor" number="12.1">
<h2><span class="header-section-number">12.1</span> Correlations<a href="linreg.html#correlations" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The ability to understand how some outcome varies with another event is not rocket science to any of us, even those who have never taken a statistics class. We all understand when two things are correlated because when we see broken windows in a neighborhood we suspect that it is an unsafe neighborhood. Or if we see clouds when we wake up we expect some rainfall before the day is done. What are we doing? Why, recognizing that there seems to be a pattern in that when we see <span class="math inline">\(x\)</span> we often see <span class="math inline">\(y\)</span>. Now, just because two things seem to occur at the same time does not mean that one causes another, to claim as such would be disregarding the long-standing adage that <code>correlation is not causation</code>. That is, just because two things are correlated does not mean one causes the other. Look hard enough and you will find ridiculous correlations, a feature of our world that has led to what started as a hilarious website and is now a book: <a href="http://www.tylervigen.com/spurious-correlations">Spurious Correlations</a>. As I write this chapter, the leading spurious correlation Tyler Vigen is displaying is of an almost perfect correlation between U.S. spending on science, technology and space and the number of suicides by hanging, strangulation and suffocation <span class="math inline">\((r = 0.9978)\)</span>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:tylervigen"></span>
<img src="images/tylervigenchart.png" alt="A Ridiculous Spurious Correlation" width="80%" />
<p class="caption">
FIGURE 12.1: A Ridiculous Spurious Correlation
</p>
</div>
<p>So one thing rapidly becomes crystal clear: Correlations do not explain anything, they just reflect a pattern in the data. It is up to us to come up with a plausible explanation for why two things covary. As we allow this point to sink in, we should also recognize that not all correlations are statistically significant. Simply put, we may see two things correlated at <span class="math inline">\(0.5\)</span> but that does not mean the correlation is statistically different from <span class="math inline">\(0\)</span>. Let us appreciate these statements in some detail.</p>
<div id="pearson-correlation-coefficient" class="section level3 hasAnchor" number="12.1.1">
<h3><span class="header-section-number">12.1.1</span> Pearson Correlation Coefficient<a href="linreg.html#pearson-correlation-coefficient" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Given two numeric variables, the degree to which they are correlated is measured via the Pearson Product-Moment Correlation Coefficient, denoted by the symbol <span class="math inline">\(r\)</span>. Mathematically, the Pearson correlation coefficient is calculated as</p>
<p><span class="math display">\[r = \dfrac{\sum \left( x_i - \bar{x} \right) \left(y_i - \bar{y} \right)}{\sqrt{ \sum \left( x_i - \bar{x} \right)^2} \sqrt{ \sum \left( y_i - \bar{y} \right)^2 }}\]</span></p>
<p>Note that <span class="math inline">\(\bar{x}\)</span> is the mean of <span class="math inline">\(x\)</span> and <span class="math inline">\(\bar{y}\)</span> is the mean of <span class="math inline">\(y\)</span>. So the numerator is just the sum of the product of the deviations of <span class="math inline">\(x_i\)</span> from its mean and of <span class="math inline">\(y_i\)</span> from its mean. The denominator is just the product of the square root of the <code>sum of squared deviations</code> of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> from their respective means. Assume that <span class="math inline">\(x = y\)</span>, i.e., the two variables are mirror images of each other. In that case, <span class="math inline">\(r\)</span> will be</p>
<p><span class="math display">\[\begin{array}{l}
r = \dfrac{\sum \left( x_i - \bar{x} \right) \left(x_i - \bar{x} \right)}{\sqrt{ \sum \left( x_i - \bar{x} \right)^2} \sqrt{ \sum \left( x_i - \bar{x} \right)^2 }} \\
= \dfrac{\sum {\left(x_i - \bar{x} \right)^2}}{\sqrt{ \sum \left( x_i - \bar{x} \right)^2} \sqrt{ \sum \left( x_i - \bar{x} \right)^2 }} \\
= \dfrac{\sum {\left(x_i - \bar{x} \right)^2}}{\sum {\left(x_i - \bar{x} \right)^2}} \\
= 1
\end{array}\]</span></p>
<p>In other words, if <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> have a one-to-one correspondence, then the two will be perfectly correlated. That is not the whole story since technically speaking the two will be perfectly positively correlated since <span class="math inline">\(r = +1\)</span>.</p>
<p>If <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> are perfectly but inversely related, then <span class="math inline">\(r = -1\)</span>, and we refer to this is a case of a perfect negative correlation. Finally, if the two are not at all correlated, then <span class="math inline">\(r = 0\)</span>. In brief, the correlation coefficient will have a specific range: <span class="math inline">\(-1 \leq r \leq +1\)</span> and cannot exceed these limits. The graph below shows you stylized correlations by way of a scatter-plot.</p>
<p><img src="images/corrplot1.png" width="70%" style="display: block; margin: auto;" /><img src="images/corrplot2.png" width="70%" style="display: block; margin: auto;" /><img src="images/corrplot3.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Notice how these plots show the pattern of the relationship between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>. In (a), we see the cloud of points tilted upwards and to the right; as the variable on the <span class="math inline">\(x\)</span> axis increases, so does the variable on the <span class="math inline">\(y\)</span> axis. In (b), we see the opposite; as the variable on the <span class="math inline">\(x\)</span> axis increases the variable on the <span class="math inline">\(y\)</span> axis decreases. The relationship isn’t that strong here so the pattern of the cloud tilted down and to the right is less obvious than in (c). In (c) it looks like a swarm of bees, all over the place, huddling in the middle, and with no pattern evident. This is no surprise because the two variables have an almost <span class="math inline">\(0\)</span> correlation. But scatter-plots alone don’t tell us whether a correlation is significant; a hypothesis test does. Given that <span class="math inline">\(r\)</span> is based on a sample it is estimating the true correlation between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> in the population, denoted by <span class="math inline">\(\rho\)</span>. One then needs to conduct a hypothesis test that will tell us whether in the population <span class="math inline">\(\rho=0\)</span> or <span class="math inline">\(\rho \neq 0\)</span>.</p>
<p><span class="math display">\[\begin{array}{l}
H_0: \rho=0 \\
H_A: \rho \neq 0
\end{array}\]</span></p>
<p>The test statistic is <span class="math inline">\(t = \dfrac{r}{SE_r}\)</span>; where <span class="math inline">\(SE_r = \sqrt{\dfrac{1-r^2}{n-2}}\)</span> and as usual we reject <span class="math inline">\(H_0\)</span> if <span class="math inline">\(p-value \leq \alpha\)</span>. We can also calculate asymptotic approximate confidence intervals for <span class="math inline">\(\rho\)</span> as</p>
<p><span class="math display">\[z - 1.96\sigma_z &lt; \zeta &lt; z + 1.96\sigma_z \text{ where } z=0.5ln\left( \dfrac{1+r}{1-r} \right)\]</span></p>
<p>where <span class="math inline">\(\sigma_z = \sqrt{\dfrac{1}{n-3}}\)</span> and <span class="math inline">\(\zeta\)</span> is the population analogue of the <span class="math inline">\(z\)</span> used to calculate confidence intervals. Because the <span class="math inline">\(z\)</span> involves the natural logarithm we back-transform via taking the antilog of the lower and upper bounds of the confidence interval.</p>
<p>Let us see scatter-plots and correlations in action with some real-world data to get a feel for patterns we might encounter.</p>
<div id="example-1-13" class="section level4 unnumbered hasAnchor">
<h4>Example 1<a href="linreg.html#example-1-13" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><a href="http://www.countyhealthrankings.org/our-approach">The Robert Wood Johnson Foundation’s County Health Rankings</a> measure the health of nearly all counties in the nation and rank them within states. The Rankings are compiled using county-level measures from a variety of national and state data sources. The rankings employ a number of measures but those of interest and in use below are: (a) Premature Death (Years of potential life lost before age 75 per 100,000 population), (b) Adult Obesity (Percentage of adults that report a BMI of 30 or more), (c) Physical Inactivity (Percentage of adults aged 20 and over reporting no leisure-time physical activity
), (d) Uninsured (Percentage of population under age 65 without health insurance), (e) High School Graduation (Percentage of ninth-grade cohort that graduates in four years), and (f) Unemployment (Percentage of population ages 16 and older unemployed but seeking work).</p>
<p>If we look at all unique pairs of these variables, what should we expect? Well, I would expect premature death to be positively correlated with obesity, physical inactivity, uninsured, unemployment, and negatively correlated with high school graduation (under the belief that if you have <span class="math inline">\(\geq\)</span> high school education you are more likely to be employed, insured, etc).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:chr2"></span>
<img src="_stats_files/figure-html/chr2-1.svg" alt="Correlations in the County Health Rankings" width="75%" /><img src="_stats_files/figure-html/chr2-2.svg" alt="Correlations in the County Health Rankings" width="75%" /><img src="_stats_files/figure-html/chr2-3.svg" alt="Correlations in the County Health Rankings" width="75%" />
<p class="caption">
FIGURE 12.2: Correlations in the County Health Rankings
</p>
</div>
<p>I’ll setup a single pair of hypotheses so that you get the basic idea.</p>
<p><span class="math display">\[\begin{array}{l}
H_0: \text{ Adult Obesity and Premature Death are not correlated } (\rho = 0) \\
H_1: \text{ Adult Obesity and Premature Death ARE correlated } (\rho \neq 0)
\end{array}\]</span></p>
<p>As usual, we reject the null hypothesis if <span class="math inline">\(p-value \leq \alpha\)</span></p>
<p>In (a) and (b) we see a positive relationship with premature death increasing as adult obesity increases and uninsured rates increase, respectively. In (c), however, we see a negative relationship with premature death decreasing as high school graduation rates increase. The estimated correlation coefficients and <span class="math inline">\(p-values\)</span> are: (a) <span class="math inline">\(r = 0.4966, p-value &lt; 2.2e-16\)</span>, (b) <span class="math inline">\(r = 0.3784, p-value &lt; 2.2e-16\)</span>, and (c) <span class="math inline">\(-0.1477, p-value = 1.055e-14\)</span>, with 95% confidence intervals of <span class="math inline">\(0.4697, 0.5226\)</span>, <span class="math inline">\(0.3480, 0.4081\)</span>, and <span class="math inline">\(-0.1843, -0.1107\)</span>, respectively.</p>
</div>
<div id="example-2-13" class="section level4 unnumbered hasAnchor">
<h4>Example 2<a href="linreg.html#example-2-13" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Are care insurance premiums correlated with the percentage of drivers who were involved in fatal collisions and were speeding?</p>
<p><span class="math display">\[\begin{array}{l}
H_0: \text{ Insurance premiums are not correlated with the percentage of drivers who were involved in fatal collisions and were speeding } (\rho = 0) \\
H_1: \text{ Insurance premiums ARE correlated with the percentage of drivers who were involved in fatal collisions and were speeding } (\rho \neq 0)
\end{array}\]</span></p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:chr3"></span>
<img src="_stats_files/figure-html/chr3-1.svg" alt="Correlation between fatal collisions involving speeding and insurance premiums" width="80%" />
<p class="caption">
FIGURE 12.3: Correlation between fatal collisions involving speeding and insurance premiums
</p>
</div>
<p>The estimate correlation coefficient is <span class="math inline">\(r=0.0425\)</span>, the <span class="math inline">\(p-value = 0.7669\)</span>, and the 95% confidence interval is <span class="math inline">\((-0.2358, 0.3144\)</span>). Quite clearly we cannot reject the null; there is no correlation between the two metrics. You may have been surprised by these estimates since the plot may have lead you to expect a positive correlation. Well, a picture (and our a priori expectations) can always be at odds with the truth. Stereotypes, anyone??</p>
</div>
<div id="assumptions-of-the-pearson-correlation-coefficient" class="section level4 hasAnchor" number="12.1.1.1">
<h4><span class="header-section-number">12.1.1.1</span> Assumptions of the Pearson Correlation Coefficient<a href="linreg.html#assumptions-of-the-pearson-correlation-coefficient" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The Correlation Coefficient is based on the assumption of <code>bivariate normality</code>:</p>
<ol style="list-style-type: decimal">
<li>That <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> are each normally distributed – this assumption can be tested via the usual approaches to testing for normality. For our purposes, however, we will assume that normality holds.</li>
<li>That <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> are linearly related – the Pearson correlation coefficient applies to linear relationships so if <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> are non-linearly related the Pearson correlation coefficient should not be used.</li>
<li>That the cloud of points characterized by pairs of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> has a circular or elliptical shape – this assumption can be visually checked.</li>
</ol>
<p>If these assumptions are violated, we have some fallback solutions but those go beyond the purview of this course. We also will not worry about testing these assumptions for now.</p>
</div>
</div>
<div id="spearman-correlation-coefficient" class="section level3 hasAnchor" number="12.1.2">
<h3><span class="header-section-number">12.1.2</span> Spearman Correlation Coefficient<a href="linreg.html#spearman-correlation-coefficient" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>While the Pearson correlation coefficient is designed for numeric variables, what if the measures are ordinal, such as states ranked by how healthy their populations are, counties ranked by the number of opioid deaths, or students ranked on the basis of their cumulative GPAs? Well, in these instances, where we have ordinal data, the <code>Spearman correlation coefficient</code> comes into use. Technically, the Spearman correlation coefficient measures the strength and association between the <strong>ranks</strong> of two variables assumed to be (i) randomly sampled, and (ii) with linearly related ranks. Again, we will not test these assumptions (since (i) is assumed to be true and testing (ii) is beyond our current scope). The mechanics are fairly simple:</p>
<ol style="list-style-type: decimal">
<li>Rank the scores of each variable separately, from low to high</li>
<li>Average the ranks in the presence of ties</li>
<li>Calculate <span class="math inline">\(r_s=\dfrac{\sum \left(R - \bar{R} \right)\left( S - \bar{S}\right) }{\sum \left(R - \bar{R} \right)^2 \sum \left(S - \bar{S} \right)^2}\)</span></li>
<li><span class="math inline">\(H_0\)</span>: <span class="math inline">\(\rho_s = 0\)</span>; <span class="math inline">\(H_1\)</span>: <span class="math inline">\(\rho_s \neq 0\)</span></li>
<li>Set <span class="math inline">\(\alpha\)</span></li>
<li>Reject <span class="math inline">\(H_0\)</span> if <span class="math inline">\(P-value \leq \alpha\)</span>; Do not reject <span class="math inline">\(H_0\)</span> otherwise</li>
</ol>
<p>Let us see a particularly interesting example.</p>
<div id="example-1-14" class="section level4 hasAnchor" number="12.1.2.1">
<h4><span class="header-section-number">12.1.2.1</span> Example 1<a href="linreg.html#example-1-14" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>How reliable are witness accounts of “miracles”? One means of testing this is by comparing different accounts of extraordinary magic tricks. Of the many illusions performed by magicians, none is more renowned than the Indian rope trick. In brief, a magician tosses the end of a rope into the air and the rope forms a rigid pole. A boy climbs up the rope and disappears at the top. The magicians scolds the boy and asks him to return but with no response, and so climbs the rope himself, with a knife in hand, and does not return. The boy’s body falls in pieces from the sky into a basket on the ground. The magician then drops back to the ground and retrieves the boy from the basket, revealing him to be unharmed and in one piece.</p>
<p>Researchers tracked down 21 first-hand accounts and scored each narrative according to how impressive it was, on a scale of 1 to 5. The researchers also recorded the number of years that had lapsed between the date that the trick was witnessed and the date when the memory of the trick being performed was written down. Is there any association between the impressiveness of eyewitness accounts and the time lapsed since the account was penned?</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:spearman1"></span>
<img src="_stats_files/figure-html/spearman1-1.svg" alt="The Indian rope trick" width="70%" />
<p class="caption">
FIGURE 12.4: The Indian rope trick
</p>
</div>
<p>The figure is hard to read but it looks as if the more the years that have lapsed the higher the impressiveness score. The estimated correlation is <span class="math inline">\(0.7843\)</span> and has a <span class="math inline">\(p-value = 2.571e-05\)</span>. The null hypothesis, of no correlation, is soundly rejected.</p>
</div>
<div id="example-2-14" class="section level4 hasAnchor" number="12.1.2.2">
<h4><span class="header-section-number">12.1.2.2</span> Example 2<a href="linreg.html#example-2-14" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>You may have heard about the <a href="http://www.oecd.org/pisa/">PISA Report</a> every now and then when there are moans and groans about how the United States is performing academically compared to other Organization for Economic Cooperation and Development (OECD) nations. The report ranks countries in terms of students’ academic achievements and while it has its detractors (largely because of how the data are generated), PISA remains one of those obelisks policymakers and politicians can’t help but stare at even if they wished it would crumble into a mound of stand before next Monday. Well, if we look at how countries rank in terms of reading scores versus mathematics scores, what do we see? Are country ranks on these subjects correlated? Here is the scatter-plot:</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:spearman2"></span>
<img src="_stats_files/figure-html/spearman2-1.svg" alt="PISA ranks on Reading and Mathematics" width="70%" />
<p class="caption">
FIGURE 12.5: PISA ranks on Reading and Mathematics
</p>
</div>
<p><span class="math display">\[\begin{array}{l}
H_0: \text{ Countries&#39; ranks on reading and mathematics are not correlated } (\rho_s = 0) \\
H_1: \text{ Countries&#39; ranks on reading and mathematics ARE correlated } (\rho_s \neq 0)
\end{array}\]</span></p>
<p>Quite clearly, countries’ ranks on reading and mathematics are highly correlated. The estimated correlation is <span class="math inline">\(r_s = 0.9374\)</span> with a <span class="math inline">\(p-value &lt; 2.2e-16\)</span>, allowing us to easily reject the null hypothesis of no correlation.</p>
</div>
</div>
</div>
<div id="bivariate-regression" class="section level2 hasAnchor" number="12.2">
<h2><span class="header-section-number">12.2</span> Bivariate Regression<a href="linreg.html#bivariate-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Do tall parents beget tall children? That was the question Sir Francis Galton grappled with questions of heredity, asking, among other things, whether parents pass on their traits to their offspring. What began as an inquiry with seeds turned into a study of the heights of children. What Galton realized was that regardless of parents’ average heights, children tended towards the average height of children of parents with a given height. In his own words, “It appeared from these experiments that the offspring did not tend to resemble their parents in size, but always to be more mediocre than they – to be smaller than the parents, if the parents were large; to be larger than the parents, if the parents were small.”. This finding, since enshrined as the concept of <code>regression to the mean</code>, is the foundation of what we call regression analysis. We can explore Sir Galton’s point by examining the very data he worked with.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:galton"></span>
<img src="_stats_files/figure-html/galton-1.svg" alt="Sir Francis Galton's data: Heights of parents and children" width="70%" />
<p class="caption">
FIGURE 12.6: Sir Francis Galton’s data: Heights of parents and children
</p>
</div>
<p>The scatter-plot emphasizes a few features of the data. First, there does seem to be an upward tilt to the cloud of data points, suggesting that on average as parents’ mid-height increases, so does the children’s height. In fact, the correlation is <span class="math inline">\(r=0.4587\)</span> with <span class="math inline">\(p-value &lt; 2.2e-16\)</span>, and so we can be confident that the two are indeed significantly and positively correlated. Second, every mid-height of the parents has children of multiple heights, rendering quite clearly the fact that there isn’t a <span class="math inline">\(1:1\)</span> relationship between parents’ average heights and children’s heights. Sometimes children are taller and other times they are shorter than their parents.</p>
<table class="table table-striped" style="font-size: 12px; width: auto !important; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:galton2">TABLE 12.1: </span>Mean Child height per Parent height
</caption>
<thead>
<tr>
<th style="text-align:right;">
Parent’s height
</th>
<th style="text-align:right;">
Mean Child height
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
64.0
</td>
<td style="text-align:right;">
65.3
</td>
</tr>
<tr>
<td style="text-align:right;">
64.5
</td>
<td style="text-align:right;">
65.4
</td>
</tr>
<tr>
<td style="text-align:right;">
65.5
</td>
<td style="text-align:right;">
66.7
</td>
</tr>
<tr>
<td style="text-align:right;">
66.5
</td>
<td style="text-align:right;">
67.1
</td>
</tr>
<tr>
<td style="text-align:right;">
67.5
</td>
<td style="text-align:right;">
67.6
</td>
</tr>
<tr>
<td style="text-align:right;">
68.5
</td>
<td style="text-align:right;">
68.0
</td>
</tr>
<tr>
<td style="text-align:right;">
69.5
</td>
<td style="text-align:right;">
68.7
</td>
</tr>
<tr>
<td style="text-align:right;">
70.5
</td>
<td style="text-align:right;">
69.6
</td>
</tr>
<tr>
<td style="text-align:right;">
71.5
</td>
<td style="text-align:right;">
70.1
</td>
</tr>
<tr>
<td style="text-align:right;">
72.5
</td>
<td style="text-align:right;">
71.9
</td>
</tr>
<tr>
<td style="text-align:right;">
73.0
</td>
<td style="text-align:right;">
73.0
</td>
</tr>
</tbody>
</table>
<p>What is the average height of the children for each parent mid-height? This is easily calculated, and has been tabulated for you below. The key point of this table is to illustrate the increasing average height of the child per increase in the parent mid-height. So when we encounter parents who have an average height of say 64 inches our best bet of their child’s height would be 65.3 inches, and so on. These mean heights of the children are plotted for you in the figure below. Notice that the line connecting these means is not a straight line.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:galton3"></span>
<img src="_stats_files/figure-html/galton3-1.svg" alt="Sir Francis Galton's data: Heights of parents and children" width="70%" />
<p class="caption">
FIGURE 12.7: Sir Francis Galton’s data: Heights of parents and children
</p>
</div>
<p>What does any of this have to do with regression analysis? Everything. How? Because regression analysis revolves around trying to fit a straight line through a cloud of points representing pairs of values of two variables <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>. The variable <span class="math inline">\(y\)</span> is what we will call our <code>dependent variable</code> and will be numeric and continuous while <span class="math inline">\(x\)</span> is out <code>independent variable</code> and can be either numeric or categorical. To aid our grasp of regression analysis we will restrict <span class="math inline">\(x\)</span> to be a numeric variable for the moment but relax this requirement down the road.</p>
<p>How could we fit a straight line through Galton’s data? By recalling the equation for a straight line: <span class="math inline">\(y = m(x) + c\)</span> where <span class="math inline">\(m\)</span> is the slope of the line and <span class="math inline">\(c\)</span> is in the intercept. Given two sets of coordinates <span class="math inline">\((x_1,y_1), (x_2,y_2)\)</span>, say <span class="math inline">\((-1,-1)\)</span> and <span class="math inline">\((5, 1)\)</span> respectively, we can calculate the slope of the straight line connecting these two points as <span class="math inline">\(b = \dfrac{y_2 - y_1}{x_2 - x_1} = \dfrac{1 - (-1)}{5 - (-1)} = \dfrac{2}{6}=0.333\)</span>. This works for more than two data points as well, as shown below with a simple data-set.</p>
<table class="table table-striped" style="font-size: 12px; width: auto !important; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:regdemotable">TABLE 12.2: </span>A small data-set for regression
</caption>
<thead>
<tr>
<th style="text-align:right;">
x
</th>
<th style="text-align:right;">
y
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
-1
</td>
<td style="text-align:right;">
-1.000
</td>
</tr>
<tr>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-0.667
</td>
</tr>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
-0.333
</td>
</tr>
<tr>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
0.000
</td>
</tr>
<tr>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
0.333
</td>
</tr>
<tr>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
0.667
</td>
</tr>
<tr>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
1.000
</td>
</tr>
</tbody>
</table>
<p>Given these data, we can calculate the intercept <span class="math inline">\((a)\)</span> by finding the value of <span class="math inline">\(y\)</span> when <span class="math inline">\(x=0\)</span>. So one set of coordinates we want are <span class="math inline">\((0, y_0)\)</span>, and a second set picked arbitrarily could be <span class="math inline">\((5,1)\)</span>. Note that <span class="math inline">\(y_0\)</span> is the unknown value of the intercept <span class="math inline">\(a\)</span>. Now, the slope is calculated for these pairs of points as</p>
<p><span class="math display">\[b = \dfrac{1 - y_0}{5 - 0}=\dfrac{1-y_0}{5}\]</span></p>
<p>Since we calculated the slope before we know the slope is 0.333, i.e., <span class="math inline">\(b=0.333\)</span>. Substitute the value of the slope in the equation above and solve for the intercept <span class="math inline">\(y_0\)</span>.</p>
<p><span class="math display">\[\begin{array}{l}
b = \dfrac{1-y_0}{5} \\
0.333 = \dfrac{1-y_0}{5} \\
\therefore 0.333 \times 5 = 1 - y_0 \\
\therefore (0.333 \times 5) - 1 = - y_0 \\
\therefore 1.665 - 1 = - y_0 \\
\text{multiply both sides of the equation to get rid of } -1 \text{ and rearrange}\\
\therefore y_0 = 1 - 1.665 = -0.665
\end{array}\]</span></p>
<p>We have both our slope and the intercept so we can write the equation for the straight line connecting the pairs of <span class="math inline">\((x,y)\)</span> points as: <span class="math inline">\(y = m(x) + c = 0.333(x) - 0.665\)</span>. Given this equation we can find the value of <span class="math inline">\(y\)</span> for any given value of <span class="math inline">\(x\)</span>.</p>
<ul>
<li>When <span class="math inline">\(x=0\)</span> <span class="math inline">\(y = 0.333(0) - 0.665 = -0.665\)</span></li>
<li>When <span class="math inline">\(x=1\)</span> <span class="math inline">\(y = 0.333(1) - 0.665 = -0.332\)</span></li>
<li>When <span class="math inline">\(x=2\)</span> <span class="math inline">\(y = 0.333(2) - 0.665 = 0.001\)</span></li>
<li>When <span class="math inline">\(x=3\)</span> <span class="math inline">\(y = 0.333(3) - 0.665 = 0.334\)</span></li>
<li>When <span class="math inline">\(x=4\)</span> <span class="math inline">\(y = 0.333(4) - 0.665 = 0.667\)</span></li>
<li>When <span class="math inline">\(x=5\)</span> <span class="math inline">\(y = 0.333(5) - 0.665 = 1.000\)</span></li>
</ul>
<p>As <span class="math inline">\(x\)</span> increases by <span class="math inline">\(1\)</span>, <span class="math inline">\(y\)</span> increases by <span class="math inline">\(0.333\)</span>. That is the very definition for the slope of a straight line: The slope indicates how much <span class="math inline">\(y\)</span> changes by for a unit change in <span class="math inline">\(x\)</span>. Unit change, in our case, will be treated as an increase of exactly <span class="math inline">\(1\)</span>, so bear that in mind. Let us now plot these data points and draw the straight line we calculated through the cloud of points.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:cloud"></span>
<img src="_stats_files/figure-html/cloud-1.svg" alt="The regression line and cloud of points" width="70%" />
<p class="caption">
FIGURE 12.8: The regression line and cloud of points
</p>
</div>
<p>In this case we have a single value of <span class="math inline">\(y\)</span> for a single value of <span class="math inline">\(x\)</span>, unlike the Galton data where for each value of <span class="math inline">\(x\)</span> (parents’ average height) we had children of different heights <span class="math inline">\((y)\)</span>. What would the straight line look like in that case? Let us redraw the plot of parents’ and children’s heights with the straight line superimposed on the cloud of points.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:galton4"></span>
<img src="_stats_files/figure-html/galton4-1.svg" alt="Sir Francis Galton's data: Heights of parents and children" width="70%" />
<p class="caption">
FIGURE 12.9: Sir Francis Galton’s data: Heights of parents and children
</p>
</div>
<p>Given the multiple <span class="math inline">\(y\)</span> values for each <span class="math inline">\(x\)</span> value we knew the straight line could not touch every point. Instead, it runs through the middle of the range of <span class="math inline">\(x\)</span> values for each <span class="math inline">\(y\)</span>, except for the maximum value of <span class="math inline">\(x\)</span> where both points are well above the line. How close does this line come to the average of children’s heights calculated for each parent mid-height? Quite well, it turns out, except for the two highest values of parents’ mid-heights.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:galton5"></span>
<img src="_stats_files/figure-html/galton5-1.svg" alt="Sir Francis Galton's data: Heights of parents and children" width="70%" />
<p class="caption">
FIGURE 12.10: Sir Francis Galton’s data: Heights of parents and children
</p>
</div>
<p>This demonstrates an important principle of the regression line: It will try to fit itself such that it minimizes the distance between itself and all the data points. Once it is fit, there is no way to rotate it up or down without making at least one data point farther away from the resulting line than was the case before. Hence the regression line is often also referred to as the <code>line of best fit</code> and the method of obtaining the estimates of the regression line as the method of <code>ordinary least squares (OLS)</code>.</p>
<p>What if we used this line to predict a child’s height? Well, your prediction would be close to reality but the child could be taller or shorter than your predicted height. This drift we refer to as <code>errors</code>, and because these errors will occur, no matter how much we try to minimize them, we start writing the equation for the regression line as <span class="math inline">\(y = \alpha + \beta(x) + \epsilon\)</span> where <span class="math inline">\(\alpha = intercept\)</span>, <span class="math inline">\(\beta = slope\)</span> and <span class="math inline">\(\epsilon = errors\)</span>. In Galton’s data, the slope is estimated to be <span class="math inline">\(0.6463\)</span> and the intercept is <span class="math inline">\(23.9415\)</span>, rendering the equation to be</p>
<p><span class="math display">\[\begin{array}{l}
y = 23.9415 + 0.6463(x) \\
i.e., \text{ child&#39;s height } = 23.9415 + 0.6463(\text{ parents&#39; mid-height })
\end{array}\]</span></p>
<p>The errors <span class="math inline">\((\epsilon)\)</span> represent the drift between the actual <span class="math inline">\(y_i\)</span> value and the predicted value of y that is denoted as <span class="math inline">\(\hat{y}_i\)</span>, i.e., <span class="math inline">\(\epsilon_i = y_i - \hat{y}_i\)</span>. These errors reflect the fact that our regression line is either underestimating or overestimating actual <span class="math inline">\(y\)</span> values and so the amount of overestimation/underestimation is called the <code>residuals</code> – something left over by the regression line. For the estimated regression line, here are the <span class="math inline">\(\hat{y}_i\)</span> (the predicted values of <span class="math inline">\((y_i)\)</span> and the residuals <span class="math inline">\((\hat{e}_i)\)</span> for a snippet of the data.</p>
<table class="table table-striped" style="font-size: 12px; width: auto !important; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:ols">TABLE 12.3: </span>Predicted values and Residuals
</caption>
<thead>
<tr>
<th style="text-align:right;">
Parent’s mid-height
</th>
<th style="text-align:right;">
Child’s height
</th>
<th style="text-align:right;">
Predicted Child’s height
</th>
<th style="text-align:right;">
Residual
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
64.0
</td>
<td style="text-align:right;">
61.7
</td>
<td style="text-align:right;">
65.3
</td>
<td style="text-align:right;">
-3.6
</td>
</tr>
<tr>
<td style="text-align:right;">
64.0
</td>
<td style="text-align:right;">
63.2
</td>
<td style="text-align:right;">
65.3
</td>
<td style="text-align:right;">
-2.1
</td>
</tr>
<tr>
<td style="text-align:right;">
64.0
</td>
<td style="text-align:right;">
63.2
</td>
<td style="text-align:right;">
65.3
</td>
<td style="text-align:right;">
-2.1
</td>
</tr>
<tr>
<td style="text-align:right;">
64.0
</td>
<td style="text-align:right;">
64.2
</td>
<td style="text-align:right;">
65.3
</td>
<td style="text-align:right;">
-1.1
</td>
</tr>
<tr>
<td style="text-align:right;">
64.0
</td>
<td style="text-align:right;">
64.2
</td>
<td style="text-align:right;">
65.3
</td>
<td style="text-align:right;">
-1.1
</td>
</tr>
<tr>
<td style="text-align:right;">
64.0
</td>
<td style="text-align:right;">
64.2
</td>
<td style="text-align:right;">
65.3
</td>
<td style="text-align:right;">
-1.1
</td>
</tr>
<tr>
<td style="text-align:right;">
64.0
</td>
<td style="text-align:right;">
64.2
</td>
<td style="text-align:right;">
65.3
</td>
<td style="text-align:right;">
-1.1
</td>
</tr>
<tr>
<td style="text-align:right;">
64.0
</td>
<td style="text-align:right;">
65.2
</td>
<td style="text-align:right;">
65.3
</td>
<td style="text-align:right;">
-0.1
</td>
</tr>
<tr>
<td style="text-align:right;">
64.0
</td>
<td style="text-align:right;">
66.2
</td>
<td style="text-align:right;">
65.3
</td>
<td style="text-align:right;">
0.9
</td>
</tr>
<tr>
<td style="text-align:right;">
64.0
</td>
<td style="text-align:right;">
66.2
</td>
<td style="text-align:right;">
65.3
</td>
<td style="text-align:right;">
0.9
</td>
</tr>
<tr>
<td style="text-align:right;">
64.0
</td>
<td style="text-align:right;">
67.2
</td>
<td style="text-align:right;">
65.3
</td>
<td style="text-align:right;">
1.9
</td>
</tr>
<tr>
<td style="text-align:right;">
64.0
</td>
<td style="text-align:right;">
67.2
</td>
<td style="text-align:right;">
65.3
</td>
<td style="text-align:right;">
1.9
</td>
</tr>
<tr>
<td style="text-align:right;">
64.0
</td>
<td style="text-align:right;">
68.2
</td>
<td style="text-align:right;">
65.3
</td>
<td style="text-align:right;">
2.9
</td>
</tr>
<tr>
<td style="text-align:right;">
64.0
</td>
<td style="text-align:right;">
69.2
</td>
<td style="text-align:right;">
65.3
</td>
<td style="text-align:right;">
3.9
</td>
</tr>
<tr>
<td style="text-align:right;">
64.5
</td>
<td style="text-align:right;">
61.7
</td>
<td style="text-align:right;">
65.6
</td>
<td style="text-align:right;">
-3.9
</td>
</tr>
<tr>
<td style="text-align:right;">
64.5
</td>
<td style="text-align:right;">
62.2
</td>
<td style="text-align:right;">
65.6
</td>
<td style="text-align:right;">
-3.4
</td>
</tr>
<tr>
<td style="text-align:right;">
64.5
</td>
<td style="text-align:right;">
63.2
</td>
<td style="text-align:right;">
65.6
</td>
<td style="text-align:right;">
-2.4
</td>
</tr>
<tr>
<td style="text-align:right;">
64.5
</td>
<td style="text-align:right;">
63.2
</td>
<td style="text-align:right;">
65.6
</td>
<td style="text-align:right;">
-2.4
</td>
</tr>
<tr>
<td style="text-align:right;">
64.5
</td>
<td style="text-align:right;">
63.2
</td>
<td style="text-align:right;">
65.6
</td>
<td style="text-align:right;">
-2.4
</td>
</tr>
<tr>
<td style="text-align:right;">
64.5
</td>
<td style="text-align:right;">
63.2
</td>
<td style="text-align:right;">
65.6
</td>
<td style="text-align:right;">
-2.4
</td>
</tr>
<tr>
<td style="text-align:right;">
64.5
</td>
<td style="text-align:right;">
64.2
</td>
<td style="text-align:right;">
65.6
</td>
<td style="text-align:right;">
-1.4
</td>
</tr>
<tr>
<td style="text-align:right;">
64.5
</td>
<td style="text-align:right;">
64.2
</td>
<td style="text-align:right;">
65.6
</td>
<td style="text-align:right;">
-1.4
</td>
</tr>
<tr>
<td style="text-align:right;">
64.5
</td>
<td style="text-align:right;">
64.2
</td>
<td style="text-align:right;">
65.6
</td>
<td style="text-align:right;">
-1.4
</td>
</tr>
<tr>
<td style="text-align:right;">
64.5
</td>
<td style="text-align:right;">
64.2
</td>
<td style="text-align:right;">
65.6
</td>
<td style="text-align:right;">
-1.4
</td>
</tr>
<tr>
<td style="text-align:right;">
64.5
</td>
<td style="text-align:right;">
65.2
</td>
<td style="text-align:right;">
65.6
</td>
<td style="text-align:right;">
-0.4
</td>
</tr>
<tr>
<td style="text-align:right;">
64.5
</td>
<td style="text-align:right;">
66.2
</td>
<td style="text-align:right;">
65.6
</td>
<td style="text-align:right;">
0.6
</td>
</tr>
<tr>
<td style="text-align:right;">
64.5
</td>
<td style="text-align:right;">
66.2
</td>
<td style="text-align:right;">
65.6
</td>
<td style="text-align:right;">
0.6
</td>
</tr>
<tr>
<td style="text-align:right;">
64.5
</td>
<td style="text-align:right;">
66.2
</td>
<td style="text-align:right;">
65.6
</td>
<td style="text-align:right;">
0.6
</td>
</tr>
<tr>
<td style="text-align:right;">
64.5
</td>
<td style="text-align:right;">
66.2
</td>
<td style="text-align:right;">
65.6
</td>
<td style="text-align:right;">
0.6
</td>
</tr>
<tr>
<td style="text-align:right;">
64.5
</td>
<td style="text-align:right;">
66.2
</td>
<td style="text-align:right;">
65.6
</td>
<td style="text-align:right;">
0.6
</td>
</tr>
</tbody>
</table>
<ul>
<li>When <span class="math inline">\(x = 64.0, \hat{y} = 65.3, y = 61.7\)</span> and hence <span class="math inline">\(\epsilon = 61.7 - 65.3 = -3.6\)</span></li>
<li>When <span class="math inline">\(x = 64.0, \hat{y} = 65.3, y = 63.2\)</span> and hence <span class="math inline">\(\epsilon = 63.2 - 65.3 = -2.1\)</span></li>
<li><span class="math inline">\(\ldots\)</span></li>
<li>When <span class="math inline">\(x = 64.0, \hat{y} = 65.3, y = 65.2\)</span> and hence <span class="math inline">\(\epsilon = 65.2 - 65.3 = -0.1\)</span></li>
<li>When <span class="math inline">\(x = 64.0, \hat{y} = 65.3, y = 66.2\)</span> and hence <span class="math inline">\(\epsilon = 66.2 - 65.3 = 0.9\)</span>
8 <span class="math inline">\(\ldots\)</span></li>
</ul>
<p>The residual is the smallest when predicted <span class="math inline">\(y\)</span> and actual <span class="math inline">\(y\)</span> are close. If they were the same, the residual would be <span class="math inline">\(0\)</span>. Now, what is the mean of <span class="math inline">\(y\)</span> when <span class="math inline">\(x = 64.0\)</span>? This was <span class="math inline">\(65.3\)</span>. So the predicted value of <span class="math inline">\(y | x = 64.0\)</span> is being calculated as the average height of all children born to parents with mid-heights of <span class="math inline">\(64.0\)</span> inches. This why the predicted value of a child’s height is always <span class="math inline">\(65.3\)</span> for these parents. In this sense, a predicted value from a regression is really a <code>conditional mean prediction</code>, conditional, that is, on the value of <span class="math inline">\(x\)</span>. If you average all the residuals, they will be zero, i.e., <span class="math inline">\(\bar{\epsilon = 0}\)</span> and this is always true for any regression line.</p>
<p>Before we move on, note that the variance of the residuals is calculated as</p>
<p><span class="math display">\[\begin{array}{l}
var(e_i) = \dfrac{\sum\left(e_i - \bar{e}\right)^2}{n-2} \\
= \dfrac{\sum\left(e_i - 0\right)^2}{n-2} \\
= \dfrac{\sum\left(e_i\right)^2}{n-2} \\
= \dfrac{\sum\left(y_i - \hat{y}_i\right)^2}{n-2}
\end{array}\]</span></p>
<p>This is the <span class="math inline">\(\dfrac{\text{ Sum of Squares of the Residuals}}{n-2} = \text{Mean of the Sum of Squares of the Residuals} = MS_{residual}\)</span>. This is the average prediction error in squared units so if we take the square-root, we get the <code>average prediction error</code> <span class="math inline">\(RMSE = \sqrt{\text{Mean of the Sum of Squares of the Residuals}}\)</span>. The smaller is this value, the better is the regression line fitting the data.</p>
<div id="the-method-of-ordinary-least-squares" class="section level3 hasAnchor" number="12.2.1">
<h3><span class="header-section-number">12.2.1</span> The Method of Ordinary Least Squares<a href="linreg.html#the-method-of-ordinary-least-squares" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The method of ordinary least squares estimates the slope and the intercept by looking to minimize the <code>sum of squared errors (SSE)</code>, i.e., <span class="math inline">\(\sum(e_i)^2 = \sum\left(y_i - \hat{y}_i\right)^2\)</span> with the slope estimated as <span class="math inline">\(\hat{\beta} = \dfrac{\sum\left(x_i - \bar{x}\right)\left(y_i - \bar{y}\right)}{\sum\left(x_i - \bar{x}\right)^2}\)</span>. Once <span class="math inline">\(\hat{\beta}\)</span> is estimated, the intercept can be calculated via <span class="math inline">\(\hat{\alpha} = \bar{y} - \hat{\beta}\left(\bar{x}\right)\)</span>. The standard error of the slope is <span class="math inline">\(s.e._{\hat{\beta}} = \sqrt{ \dfrac{\text{Mean of the Sum of Squares of the Residuals}}{\sum\left(x_i - \bar{x}\right)^2} }\)</span>.</p>
</div>
<div id="population-regression-function-vs.-sample-regression-function" class="section level3 hasAnchor" number="12.2.2">
<h3><span class="header-section-number">12.2.2</span> Population Regression Function vs. Sample Regression Function<a href="linreg.html#population-regression-function-vs.-sample-regression-function" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now, assume that the Galton data represent the population and instead of working with the population data you have a random sample to work with. Below I have drawn four random samples, each with <span class="math inline">\(100\)</span> data points randomly selected from the Galton data-set, estimated the regression line and then plotted the cloud of points plus the regression line. What do you see as you scan the four plots?</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:galton6"></span>
<img src="_stats_files/figure-html/galton6-1.svg" alt="Four random samples from Galton's data" width="100%" />
<p class="caption">
FIGURE 12.11: Four random samples from Galton’s data
</p>
</div>
<p>Note that each sample yields different estimates as compared to the population regression line where the regression equation was <span class="math inline">\(23.94 + 0.64(x)\)</span>. This is to be expected since a sample will approximate the population but rarely be identical. Because we are dealing with a sample, we distinguish between the population regression line and the sample regression line by writing the latter as <span class="math inline">\(y = a + b(x) + e\)</span>.</p>
</div>
<div id="hypotheses" class="section level3 hasAnchor" number="12.2.3">
<h3><span class="header-section-number">12.2.3</span> Hypotheses<a href="linreg.html#hypotheses" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Of course, we need to assess both the statistical significance of our sample regression line, and how well the line fits the data. Let us look at the hypothesis tests first. We have estimated two quantities – the intercept and the slope – and hence will have two hypothesis tests.</p>
<p><span class="math display">\[\begin{array}{l}
H_0: \alpha = 0 \\
H_1: \alpha \neq 0
\end{array}\]</span></p>
<p>and</p>
<p><span class="math display">\[\begin{array}{l}
H_0: \beta = 0 \\
H_1: \beta \neq 0
\end{array}\]</span></p>
<p>The test statistic for each relies on the standard errors of <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>. In particular, the test statistic for the slope is <span class="math inline">\(t_{\hat{b}} = \dfrac{\hat{b}}{s.e._{\hat{b}}}\)</span> and if the <span class="math inline">\(p-value \leq \alpha\)</span> we reject the null that <span class="math inline">\(\beta = 0\)</span>. Likewise, for the intercept we have <span class="math inline">\(s.e._{\hat{a}} = \sqrt{MS_{residual}}\left(\sqrt{\dfrac{\sum x_i^2}{n\sum\left(x_i - \bar{x}\right)^2}} \right)\)</span>, leading to <span class="math inline">\(t_{\hat{a}} = \dfrac{\hat{a}}{s.e._{\hat{a}}}\)</span>. We can also estimate the confidence interval estimates for <span class="math inline">\(\hat{a}\)</span> and <span class="math inline">\(\hat{b}\)</span> to get a sense of the intervals within which <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are likely to fall (in the population).</p>
</div>
<div id="the-r2" class="section level3 hasAnchor" number="12.2.4">
<h3><span class="header-section-number">12.2.4</span> The <span class="math inline">\(R^2\)</span><a href="linreg.html#the-r2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In addition to the RMSE, the average prediction error, we also rely on the <span class="math inline">\(R^2\)</span>, which tells us what percent of the variation in <span class="math inline">\(y\)</span> can be explained by the regression model. How is this calculated? Well, we already calculated the sum of squares for the residuals (SSE), which was <span class="math inline">\(\sum \left(y_i - \bar{y}\right)^2\)</span>. Now, we do know that the total variation in <span class="math inline">\(y\)</span> can be calculated as <span class="math inline">\(\sum\left(y_i - \bar{y}\right)^2\)</span>, so let us label this SST. The total variation in <span class="math inline">\(y\)</span> has to be made up of the SSE and the amount of variation being captured by the regression. Let us label this latter quantity SSR, and note that it can be calculated as <span class="math inline">\(SSR = \sum\left(\hat{y}_i - \bar{y}\right)^2\)</span>. Since <span class="math inline">\(SST = SSR + SSE\)</span>, we can assess what proportion of variance in <span class="math inline">\(y\)</span> is explained by the regression by calculating <span class="math inline">\(\dfrac{SSR}{SST} \ldots\)</span> which is the <span class="math inline">\(R^2\)</span>.</p>
<p>If the regression model is terrible, <span class="math inline">\(R^2 \to 0\)</span> and if the regression model is excellent, <span class="math inline">\(R^2 \to 1\)</span>. That is, <span class="math inline">\(0 \leq R^2 \leq 1\)</span> … the <span class="math inline">\(R^2\)</span> will lie in the <span class="math inline">\(\left[0, 1\right]\)</span> interval. In practice, we adjust the <span class="math inline">\(R^2\)</span> for the number of independent variables used and rely on this adjusted <span class="math inline">\(R^2\)</span>, denoted as <span class="math inline">\(\bar{R}^2\)</span>, and calculated as <span class="math inline">\(\bar{R}^2 = 1 - \left(1 - R^2\right)\left(\dfrac{n-1}{n-k-1}\right)\)</span> where <span class="math inline">\(k =\)</span> the number of independent variables being used.</p>
</div>
<div id="confidence-intervals-vs.-prediction-intervals" class="section level3 hasAnchor" number="12.2.5">
<h3><span class="header-section-number">12.2.5</span> Confidence Intervals vs. Prediction Intervals<a href="linreg.html#confidence-intervals-vs.-prediction-intervals" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Technically speaking, <span class="math inline">\(\hat{y}_{i}\)</span> is a point estimate for <span class="math inline">\(y_{i}\)</span> because it is a single estimate and tells us nothing about the interval within which the predicted value might fall. Confidence intervals and Prediction intervals, however, do, but they are not the same thing. Specifically, while the <code>confidence interval</code> is an interval estimate of the <code>mean value of y</code> for a specific value of <span class="math inline">\(x\)</span>, the <code>prediction interval</code> is an interval estimate of the <code>predicted value of y</code> for a specific value of <span class="math inline">\(x\)</span>.</p>
<p>Given <span class="math inline">\(x_{p} =\)</span> specific value of <span class="math inline">\(x\)</span> and <span class="math inline">\(y_{p} =\)</span> specific value of <span class="math inline">\(y\)</span> for <span class="math inline">\(x = x_{p}\)</span>, <span class="math inline">\(E(y_{p}) =\)</span> expected value of <span class="math inline">\(y\)</span> given <span class="math inline">\(x = x_{p}\)</span> is defined as <span class="math inline">\(\hat{y}_{p} = \hat{a} + \hat{b}(x_{p})\)</span>. The variance is, in turn, given by var(<span class="math inline">\(\hat{y}_{p}\)</span>) <span class="math inline">\(= s^{2}_{\hat{y}_{p}} = s^{2}\left[\dfrac{1}{n} + \dfrac{(x_{p} - \bar{x})^{2}}{\sum(x_{i} - \bar{x})^{2}}\right]\)</span>, which leads to s(<span class="math inline">\(\hat{y}_{p}\)</span>) <span class="math inline">\(= s_{\hat{y}_{p}}=s\sqrt{\left[\dfrac{1}{n} + \dfrac{(x_{p} - \bar{x})^{2}}{\sum(x_{i} - \bar{x})^{2}} \right]}\)</span></p>
<p>Now, the confidence interval is given by <span class="math inline">\(\hat{y}_{p} \pm t_{\alpha/2}\left(s_{\hat{y}_p}\right)\)</span>. Every time we calculate this interval we know we could be wrong on two counts – <span class="math inline">\(b_{0}; b_{1}\)</span>. Fair enough, since both have been estimated from the data and could be wrong.</p>
<p>However, if we want to predict <span class="math inline">\(y\)</span> for some <span class="math inline">\(x\)</span> value not in the sample, we know here we could be wrong on three counts – <span class="math inline">\(b_{0}; b_{1}; \text{ and } e\)</span>. This forces an adjustment in the variance calculated earlier to now be defined as <span class="math inline">\(s^{2}_{ind} = s^{2} + s^{2}_{\hat{y}_{p}}\)</span>, where <span class="math inline">\(s^{2}_{ind} = s^{2} + s^{2}\left[\dfrac{1}{n} + \dfrac{(x_{p} - \bar{x})^{2}}{\sum(x_{i} - \bar{x})^{2}}\right] = s^{2} \left[1 + \dfrac{1}{n} + \dfrac{(x_{p} - \bar{x})^{2}}{\sum(x_{i} - \bar{x})^{2}}\right]\)</span> and hence <span class="math inline">\(s_{ind} = s\sqrt{\left[1 + \dfrac{1}{n} + \dfrac{(x_{p} - \bar{x})^{2}}{\sum(x_{i} - \bar{x})^{2}}\right]}\)</span>. The prediction interval is then calculated as <span class="math inline">\(\hat{y}_{p} \pm t_{\alpha/2}\left(s_{ind}\right)\)</span></p>
<p>With the Galton data, this is what the scatter-plot would look like with the confidence intervals and predictions intervals added to the regression line. Focus on these intervals.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:galton7"></span>
<img src="_stats_files/figure-html/galton7-1.svg" alt="Confidence vs. Prediction Intervals" width="60%" />
<p class="caption">
FIGURE 12.12: Confidence vs. Prediction Intervals
</p>
</div>
<p>Notice how much wider the prediction intervals are (the red dashed lines); this is because we have made an adjustment for the additional uncertainty surrounding an <code>individual prediction</code>. Notice also that the confidence intervals flex inward, toward the regression line, in the center of the distribution but then flew outward at either extreme of the regression line. This is a result of the fact that the regression estimates are built around <span class="math inline">\(\bar{x}\)</span> and <span class="math inline">\(\bar{y}\)</span> and hence the greatest precision we have is when we are predicting <span class="math inline">\(y\)</span> for <span class="math inline">\(\bar{x}\)</span>, i.e., when predicting <span class="math inline">\(\hat{y}_{\bar{x}} = \hat{a} + \hat{b}\left(\bar{x}\right)\)</span>.</p>
<p>To sum up our discussion of interval estimates, remember that the confidence interval is in use when predicting the average value of <span class="math inline">\(y\)</span> for a specific value of <span class="math inline">\(x\)</span>. However, when we are predicting a specific value of <span class="math inline">\(y\)</span> for a given <span class="math inline">\(x\)</span>, then the prediction interval comes into use. Further, confidence intervals will hug the regression line most closely around <span class="math inline">\(\bar{x}\)</span>, and widen as you progressively move towards <span class="math inline">\(x_{min}\)</span> and <span class="math inline">\(x_{max}\)</span>.</p>
<div id="example-1-15" class="section level4 hasAnchor" number="12.2.5.1">
<h4><span class="header-section-number">12.2.5.1</span> Example 1<a href="linreg.html#example-1-15" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<table style="border-collapse:collapse; border:none;">
<tr>
<th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; ">
 
</th>
<th colspan="3" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
child
</th>
</tr>
<tr>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; ">
Predictors
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
p
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
(Intercept)
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
30.50
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
13.42 – 47.59
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
parent
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.55
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.30 – 0.80
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;">
Observations
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="3">
100
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
R<sup>2</sup> / R<sup>2</sup> adjusted
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3">
0.161 / 0.153
</td>
</tr>
</table>
<p>With a random sample drawn from the Galton data-set, can we claim that parents’ mid-heights predict the child’s height? If they do, how good is the fit of the model? It turns out that the intercept was estimated as <span class="math inline">\(\hat{a} = 21.1143\)</span> and has a <span class="math inline">\(p-value = 0.00921\)</span> while the slope was estimated as <span class="math inline">\(0.6913\)</span> and has a <span class="math inline">\(p-value = 4.49e-08\)</span>. So both the intercept and the slope are statistically significant. The <span class="math inline">\(RMSE = 2.216\)</span> and the <span class="math inline">\(\bar{R}^2 = 0.2568\)</span>.</p>
<ul>
<li><p>When the parents’ mid-height is <span class="math inline">\(=0\)</span> the child’s height is predicted to be <span class="math inline">\(21.11\)</span> inches</p></li>
<li><p>As parents’ mid-height increases by <span class="math inline">\(1\)</span>, the child’s height increases by 0.6913 inches</p></li>
<li><p>If we used this regression model to predict a child’s height, on average our prediction error would be <span class="math inline">\(2.216\)</span> inches, i.e., we would overpredict or underpredict the child’s actual height by <span class="math inline">\(\pm 2.216\)</span> inches</p></li>
<li><p>The <span class="math inline">\(\bar{R}^2 = 0.2568\)</span>, indicating that about <span class="math inline">\(25.68\%\)</span> of the variation in the child’s height can be explained by this regression model (i.e., by using the parents’ mid-height as an independent variable)</p></li>
<li><p>The 95% confidence interval around <span class="math inline">\(\hat{a}\)</span> is <span class="math inline">\(\left[5.34, 36.88\right]\)</span>, indicating that we can be about 95% confident that the population intercept lies in the <span class="math inline">\(\left[5.34, 36.88\right]\)</span> range</p></li>
<li><p>The 95% confidence interval around <span class="math inline">\(\hat{b}\)</span> is <span class="math inline">\(\left[0.46, 0.92\right]\)</span>, indicating that we can be about 95% confident that the population slope lies in the <span class="math inline">\(\left[0.46, 0.92\right]\)</span> range</p></li>
</ul>
<p>Note that the intercept will not always make sense from a real-world perspective, i.e., you can’t have parents’ mid-height be <span class="math inline">\(0\)</span> since that would mean there are no parents! However, we retain the intercept for mathematical necessity but accommodate for the often nonsensical meaning of the intercept by not interpreting it all. It is needed for the mathematics to work out but need not be interpreted. Note also that since we are only explaining about <span class="math inline">\(25.68\%\)</span> of the variation in children’s heights, there is <span class="math inline">\(100 - 25.68 = 74.32\%\)</span> of the variation left to be explained. Maybe there are other independent variables we could have used that would do a better job of predicting the child’s height as in, for example, nutrition, physical activity, good health care during the child’s early years, and so on.</p>
</div>
<div id="example-2-15" class="section level4 hasAnchor" number="12.2.5.2">
<h4><span class="header-section-number">12.2.5.2</span> Example 2<a href="linreg.html#example-2-15" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Let us revisit the question of premature death and adult obesity. How well can we predict premature death from adult obesity? Since the original data we looked at included all counties in the U.S., I will draw a random sample of 100 counties to fit the regression model.</p>
<table style="border-collapse:collapse; border:none;">
<tr>
<th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; ">
 
</th>
<th colspan="3" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
Premature Death
</th>
</tr>
<tr>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; ">
Predictors
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
p
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
(Intercept)
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.94
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.79 – 1.10
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
Adult Obesity
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.00
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.01 – 0.01
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.626
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;">
Observations
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="3">
99
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
R<sup>2</sup> / R<sup>2</sup> adjusted
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3">
0.002 / -0.008
</td>
</tr>
</table>
<ul>
<li>The intercept is <span class="math inline">\(-28.83\)</span> but is not statistically significant since the <span class="math inline">\(p-value = 0.988\)</span></li>
<li>The slope is <span class="math inline">\(264.78\)</span> and is statistically significant given the <span class="math inline">\(p-value = -1.77e-05\)</span>, indicating that as the percent of obese adults increases by <span class="math inline">\(1\)</span>, the number of premature deaths increases by about 265.</li>
<li>The <span class="math inline">\(\bar{R}^2 = 0.1652\)</span>, indicating that we can explain about <span class="math inline">\(16.52\%\)</span> of the variation in premature deaths with this regression model.</li>
<li>The <span class="math inline">\(RMSE = 2355.516\)</span>, indicating that average prediction error would be <span class="math inline">\(\pm 2355.516\)</span> if this model were used. Note the high value here, indicative of a sizable prediction error. Being off the truth by <span class="math inline">\(2355\)</span> premature deaths is a lot!</li>
</ul>
<p>Here are the data with the scatter-plot, regression line, and confidence intervals. Note that the regression equation superimposed on the plot has estimates rounded up; hence the marginal difference between these and the estimates interpreted above. Note also that the <span class="math inline">\(R^2\)</span> is being reported, not <span class="math inline">\(\bar{R}^2\)</span>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:chrplots"></span>
<img src="_stats_files/figure-html/chrplots-1.svg" alt="Predicting Premature Death from Adult Obesity" width="70%" />
<p class="caption">
FIGURE 12.13: Predicting Premature Death from Adult Obesity
</p>
</div>
</div>
</div>
<div id="dummy-variables" class="section level3 hasAnchor" number="12.2.6">
<h3><span class="header-section-number">12.2.6</span> Dummy Variables<a href="linreg.html#dummy-variables" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In the examples so far we have worked with numeric variables – parents’ mid-height, adult obesity, and so on. However, what if we had categorical variables and wanted to examine, for example, if premature deaths vary across males and females? If public school district performance differs between Appalachian and non-Appalachian Ohio? Do carbon dioxide <span class="math inline">\(CO_2\)</span> emissions vary between the developed and the developing countries? These types on interesting questions lend themselves to regression analysis rather easily. To see how these models are fit and interpreted, let us work with a specific example. The data I will utilize span the 50 states and Washington DC for the 1977-1999 period, with information on the following variables:</p>
<ul>
<li>state = factor indicating state.</li>
<li>year = factor indicating year.</li>
<li>violent = violent crime rate (incidents per 100,000 members of the population).</li>
<li>murder = murder rate (incidents per 100,000).</li>
<li>robbery = robbery rate (incidents per 100,000).</li>
<li>prisoners = incarceration rate in the state in the previous year (sentenced prisoners per 100,000 residents; value for the previous year).</li>
<li>afam = percent of state population that is African-American, ages 10 to 64.</li>
<li>cauc = percent of state population that is Caucasian, ages 10 to 64.</li>
<li>male = percent of state population that is male, ages 10 to 29.</li>
<li>population = state population, in millions of people.</li>
<li>income = real per capita personal income in the state (US dollars).</li>
<li>density = population per square mile of land area, divided by 1,000.</li>
<li>law = factor. Does the state have a shall carry law in effect in that year? If the value is “yes”, then the state allows individuals to carry a concealed handgun provided they meet certain criteria.</li>
</ul>
<p>To keep things simple let us shrink this data-set to the year 1999. The substantive question of interest is: Do concealed carry permits reduce robberies?</p>
<p><span class="math display">\[\begin{array}{l}
H_0: \text{ Concealed carry laws have no impact on robbery rates } (\beta = 0) \\
H_1: \text{ Concealed carry laws have an impact on robbery rates } (\beta \neq 0)
\end{array}\]</span></p>
<p>The regression model that could be used would assume the following structure: <span class="math inline">\(\hat{y} = \hat{a} + \hat{b}\left(law\right) + \hat{e}\)</span>. The variable “law” is a categorical variable that assumes two values – <span class="math inline">\(x = 1\)</span> indicates the state allows concealed carry and <span class="math inline">\(x = 0\)</span> indicates that the state does not allow concealed carry. What will the regression equation look like if <span class="math inline">\(x=1\)</span> versus <span class="math inline">\(x=0\)</span>?</p>
<p><span class="math display">\[\begin{array}{l}
\hat{y} = \hat{a} + \hat{b}\left(x \right) \\
\text{When } x = 1: \hat{y} = \hat{a} + \hat{b}\left(1\right) = \hat{a} + \hat{b} \\
\text{When } x = 0: \hat{y} = \hat{a} + \hat{b}\left(0\right) = \hat{a}  
\end{array}\]</span></p>
<p>Aha! The predicted value of <span class="math inline">\(y\)</span> for states with no concealed carry laws is just the estimated intercept while the predicted value of <span class="math inline">\(y\)</span> for states with concealed carry laws is the estimated intercept <span class="math inline">\(+\)</span> the estimated slope. This tells us that difference in robbery rates between states with and without concealed carry laws is just the estimated slope <span class="math inline">\(\hat{b}\)</span>. Now on to visualizing the data and then to fitting the regression model.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:guns"></span>
<img src="_stats_files/figure-html/guns-1.svg" alt="Box-plots of Robbery rates by Law " width="65%" />
<p class="caption">
FIGURE 12.14: Box-plots of Robbery rates by Law
</p>
</div>
<table style="border-collapse:collapse; border:none;">
<tr>
<th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; ">
 
</th>
<th colspan="8" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
robbery
</th>
</tr>
<tr>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; ">
Predictors
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
std. Error
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
std. Beta
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
standardized std. Error
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col7">
standardized CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col8">
Statistic
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col9">
p
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
(Intercept)
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
155.09
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
20.33
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.34
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.21
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
114.23 – 195.94
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
-0.07 – 0.75
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
7.63
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
law [yes]
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-59.59
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
26.96
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.60
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.27
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-113.77 – -5.40
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
-1.15 – -0.05
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
-2.21
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
<strong>0.032</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;">
Observations
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="8">
51
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
R<sup>2</sup> / R<sup>2</sup> adjusted
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="8">
0.091 / 0.072
</td>
</tr>
</table>
<p>The box-plots show an outlier for law = “no” and a higher median robbery rate for the “no” group versus the “yes” group; seemingly, states without concealed carry laws have on average higher robbery rates.</p>
<p>The estimated regression line is <span class="math inline">\(\hat{y} = 155.09 -59.59\left(law\right)\)</span>. That is, states without a law are predicted to have about <span class="math inline">\(114\)</span> robberies per 100,000 persons. States with a law, on the other hand, are predicted to have almost 114 fewer robberies per 100,000 persons. Note that both the intercept and the slope are statistically significant, the <span class="math inline">\(RMSE = 95.36\)</span> and the <span class="math inline">\(\bar{R}^2 = 0.0720 = 7.20\%\)</span>.</p>
<p>Wait a minute. What about that outlier we see in the box-plot? Couldn’t that be influencing our regression estimates? Let us check by dropping that data point and re-estimating the regression model.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:guns2"></span>
<img src="_stats_files/figure-html/guns2-1.svg" alt="Box-plots of Robbery rates by Law (no outlier)" width="65%" />
<p class="caption">
FIGURE 12.15: Box-plots of Robbery rates by Law (no outlier)
</p>
</div>
<table style="border-collapse:collapse; border:none;">
<tr>
<th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; ">
 
</th>
<th colspan="8" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
robbery
</th>
</tr>
<tr>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; ">
Predictors
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
std. Error
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
std. Beta
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
standardized std. Error
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col7">
standardized CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col8">
Statistic
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col9">
p
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
(Intercept)
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
131.79
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
13.90
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.32
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.21
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
103.83 – 159.75
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
-0.11 – 0.75
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
9.48
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
law [yes]
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-36.29
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
18.26
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.55
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.28
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-73.00 – 0.42
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
-1.11 – 0.01
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
-1.99
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
0.053
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;">
Observations
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="8">
50
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
R<sup>2</sup> / R<sup>2</sup> adjusted
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="8">
0.076 / 0.057
</td>
</tr>
</table>
<p>Now, the estimated intercept is <span class="math inline">\(131.79\)</span> and statistically significant. The estimated slope is <span class="math inline">\(-36.29\)</span> and has a <span class="math inline">\(p-value = 0.0526\)</span>, and so it is not statistically significant! In brief, without the outlier, average robbery rates per 100,000 persons do not appear to differ between states with/without concealed carry laws. What is the moral of the story? <code>Regression estimates will be influenced by outliers, the more extreme the outlier, the more the influence.</code></p>
<p>The preceding example involved a two-category variable. What if the variable had three or more categories? What would the regression model look like and how would we interpret the results? Assume, for example, that we are interested in looking at the wages of men who had an annual income greater than USD 50 in 1992 and were neither self-employed nor working without pay. The sample spans men aged 18 to 70 and is drawn from the March 1988 <a href="https://www.census.gov/cps/data/cpstablecreator.html">Current Population Survey</a>. The data-set includes the following variables:</p>
<ul>
<li>wage = Wage (in dollars per week).</li>
<li>education = Number of years of education.</li>
<li>experience = Number of years of potential work experience.</li>
<li>ethnicity = Factor with levels “cauc” and “afam” (African-American).</li>
<li>smsa = Factor. Does the individual reside in a Standard Metropolitan Statistical Area (SMSA)?</li>
<li>region = Factor with levels “northeast”, “midwest”, “south”, “west”.</li>
<li>parttime = Factor. Does the individual work part-time?</li>
</ul>
<p>The question of interest here will be whether wages differ by <a href="https://www.census.gov/geo/reference/gtc/gtc_census_divreg.html">Census regions</a>.</p>
<p><span class="math display">\[\begin{array}{l}
H_0: \text{ Wages do not differ by Census regions } \\
H_1: \text{ Wages do differ by Census regions }
\end{array}\]</span></p>
<p>The variable “region” is coded as follows: <span class="math inline">\(\text{Northeast}: x=1\)</span>, <span class="math inline">\(\text{Midwest}: x=2\)</span>, <span class="math inline">\(\text{South}: x=3\)</span>, <span class="math inline">\(\text{West}: x=4\)</span>. The usual regression equation would be <span class="math inline">\(\hat{y} = \hat{a} + \hat{b}\left(x\right)\)</span>. However, with categorical variables representing some attribute that has more than 2 categories we write the regression equation in a different manner. Specifically, we create a dummy variable for each of mutually exclusive categories as follows:</p>
<p><span class="math display">\[\begin{array}{l}
\text{Northeast}: = 1 \text{ if in the Northeast }; 0 \text{ otherwise (i.e., if in the Midwest, South, West)} \\
\text{Midwest}: = 1 \text{ if in the Midwest }; 0 \text{ otherwise (i.e., if in the Northeast, South, West)} \\
\text{South}: = 1 \text{ if in the South }; 0 \text{ otherwise (i.e., if in the Northeast, Midwest, West)} \\
\text{West}: = 1 \text{ if in the West }; 0 \text{ otherwise (i.e., if in the Northeast, Midwest, South)}
\end{array}\]</span></p>
<p>This leads to the regression equation being <span class="math inline">\(\hat{y} = \hat{a} + \hat{b}_1\left(Northeast\right) + \hat{b}_2\left(Midwest\right) + \hat{b}_3\left(South\right) + \hat{b}_4\left(West\right)\)</span> but in estimating the regression model we only use three of the dummy variables. This is a general rule: With a categorical variable that results in <span class="math inline">\(k\)</span> dummy variables only <span class="math inline">\(k-1\)</span> dummy variables should be included in the model unless the intercept is excluded. How do we decide which region to leave out? The rule of thumb is to <code>leave out the modal category</code> (i.e., the category that has the highest frequency).</p>
<table class="table table-striped" style="font-size: 12px; width: auto !important; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:cps1">TABLE 12.4: </span>Frequency Table for Census Regions
</caption>
<thead>
<tr>
<th style="text-align:left;">
Census Region
</th>
<th style="text-align:right;">
Frequency
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
northeast
</td>
<td style="text-align:right;">
6441
</td>
</tr>
<tr>
<td style="text-align:left;">
midwest
</td>
<td style="text-align:right;">
6863
</td>
</tr>
<tr>
<td style="text-align:left;">
south
</td>
<td style="text-align:right;">
8760
</td>
</tr>
<tr>
<td style="text-align:left;">
west
</td>
<td style="text-align:right;">
6091
</td>
</tr>
</tbody>
</table>
<p>In this data-set, the modal category happens to be the South and so we will estimate the model as <span class="math inline">\(\hat{y} = \hat{a} + \hat{b}_1\left(Northeast\right) + \hat{b}_2\left(Midwest\right) + \hat{b}_3\left(West\right)\)</span>. Now we break this down so we know how to interpret the estimates of <span class="math inline">\(\hat{y}\)</span>:</p>
<p><span class="math display">\[\begin{array}{l}
\text{In the Northeast}: \hat{y} = \hat{a} + \hat{b}_1\left(Northeast\right) + \hat{b}_2\left(Midwest\right) + \hat{b}_3\left(West\right) = \hat{a} + \hat{b}_1\left(1\right) + \hat{b}_2\left(0\right) + \hat{b}_3\left(0\right) = \hat{a} + \hat{b}_1 \\
\text{In the Midwest}: \hat{y} = \hat{a} + \hat{b}_1\left(Northeast\right) + \hat{b}_2\left(Midwest\right) + \hat{b}_3\left(West\right) = \hat{a} + \hat{b}_1\left(0\right) + \hat{b}_2\left(1\right) + \hat{b}_3\left(0\right) = \hat{a} + \hat{b}_2 \\
\text{In the West}: \hat{y} = \hat{a} + \hat{b}_1\left(Northeast\right) + \hat{b}_2\left(Midwest\right) + \hat{b}_3\left(West\right) = \hat{a} + \hat{b}_1\left(0\right) + \hat{b}_2\left(0\right) + \hat{b}_3\left(1\right) = \hat{a} + \hat{b}_3 \\
\text{In the South}: \hat{y} = \hat{a} + \hat{b}_1\left(Northeast\right) + \hat{b}_2\left(Midwest\right) + \hat{b}_3\left(West\right) = \hat{a} + \hat{b}_1\left(0\right) + \hat{b}_2\left(0\right) + \hat{b}_3\left(0\right) = \hat{a}
\end{array}\]</span></p>
<p>Aha! Since we excluded South the, intercept <span class="math inline">\((\hat{a})\)</span> reflects the impact of being in the South. Keeping this in mind, let us see how to interpret the rest of the regression estimates shows in the regression equation below:</p>
<table style="border-collapse:collapse; border:none;">
<tr>
<th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; ">
 
</th>
<th colspan="8" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
wage
</th>
</tr>
<tr>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; ">
Predictors
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
std. Error
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
std. Beta
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
standardized std. Error
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col7">
standardized CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col8">
Statistic
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col9">
p
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
(Intercept)
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
558.31
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
4.83
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.10
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.01
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
548.84 – 567.78
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
-0.12 – -0.08
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
115.56
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
region [northeast]
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
95.73
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
7.42
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.21
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.02
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
81.18 – 110.28
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
0.18 – 0.24
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
12.90
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
region [midwest]
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
46.37
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
7.29
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.10
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.02
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
32.08 – 60.66
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
0.07 – 0.13
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
6.36
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
region [west]
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
56.46
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
7.54
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.12
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.02
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
41.68 – 71.25
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
0.09 – 0.16
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
7.48
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;">
Observations
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="8">
28155
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
R<sup>2</sup> / R<sup>2</sup> adjusted
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="8">
0.006 / 0.006
</td>
</tr>
</table>
<p><span class="math display">\[\begin{array}{l}
\hat{y} = \hat{a} + \hat{b}_1\left(Northeast\right) + \hat{b}_2\left(Midwest\right) + \hat{b}_3\left(West\right) \\
\hat{y} = 558.308 + 95.731\left(Northeast\right) + 46.371\left(Midwest\right) + 56.463\left(West\right)
\end{array}\]</span></p>
<ul>
<li>Predicted average wage in the Northeast is <span class="math inline">\(558.308 + 95.731 = 654.039\)</span></li>
<li>Predicted average wage in the Midwest is <span class="math inline">\(558.308 + 46.371 = 604.679\)</span></li>
<li>Predicted average wage in the Northeast is <span class="math inline">\(558.308 + 56.463 =  614.771\)</span></li>
<li>Predicted average wage in the South is <span class="math inline">\(558.308\)</span></li>
</ul>
<p>The <span class="math inline">\(p-values\)</span> are basically <span class="math inline">\(0\)</span> for the intercept and the the three dummy variables and hence these results suggest that region does matter; wages differ by Census region, with those in the Northeast having the highest average wage, followed by the Northeast, then the Midwest, and finally the West. In closing, the <span class="math inline">\(RMSE = 452.2\)</span> and the <span class="math inline">\(\bar{R}^2 = 0.005959 = 0.5959\%\)</span>. Clearly this is a terrible regression model because we are hardly explaining any of the variation in wages.</p>
</div>
</div>
<div id="multiple-regression" class="section level2 hasAnchor" number="12.3">
<h2><span class="header-section-number">12.3</span> Multiple Regression<a href="linreg.html#multiple-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Thus far we have restricted out attention to a single independent variable, largely because it is easier to understand the logic of regression analysis with a single independent variable. However, few things, if any, can be explained by looking at a single independent variable. Instead, we often have to include multiple independent variables because the phenomenon the dependent variable represents is extremely complex. For example, think about trying to predict stock prices, climate change, election results, students’ academic performance, health outcomes, and so on. None of these are easy phenomenon to comprehend, leave alone capture via a single independent variable. Consequently, we now turn to the more interesting world of <code>multiple regression analysis</code> We will start with at least two independent variables, each of which may be numeric or categorical. For ease of comprehension I’ll stick with the wage data-set.</p>
<p>Say we have two independent variables, <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>. Now the regression equation is specified as</p>
<p><span class="math display">\[\hat{y} = \hat{a} + \hat{b}_1\left( x_1  \right) + \hat{b}_2\left( x_2  \right)\]</span></p>
<p>With three independent variables the equation becomes</p>
<p><span class="math display">\[\hat{y} = \hat{a} + \hat{b}_1\left( x_1  \right) + \hat{b}_2\left( x_2  \right) + \hat{b}_3\left( x_3  \right)\]</span></p>
<p>and so on.</p>
<p>Now the way we interpret <span class="math inline">\(\hat{a}, \hat{b}_1, \hat{b}_2, \text{ and } \hat{b}_3\)</span> changes. Specifically,</p>
<ul>
<li><span class="math inline">\(\hat{a}\)</span> is the predicted value of <span class="math inline">\(y\)</span> when all independent variables are <span class="math inline">\(=0\)</span></li>
<li><span class="math inline">\(\hat{b}_1\)</span> is the <em>partial slope coefficient</em> on <span class="math inline">\(x_1\)</span> and indicates the change in <span class="math inline">\(y\)</span> for a unit change in <span class="math inline">\(x_1\)</span> <em>holding all other independent variables constant</em></li>
<li><span class="math inline">\(\hat{b}_2\)</span> is the <em>partial slope coefficient</em> on <span class="math inline">\(x_2\)</span> and indicates the change in <span class="math inline">\(y\)</span> for a unit change in <span class="math inline">\(x_2\)</span> <em>holding all other independent variables constant</em></li>
<li><span class="math inline">\(\hat{b}_3\)</span> is the <em>partial slope coefficient</em> on <span class="math inline">\(x_3\)</span> and indicates the change in <span class="math inline">\(y\)</span> for a unit change in <span class="math inline">\(x_3\)</span> <em>holding all other independent variables constant</em></li>
<li>and so on</li>
</ul>
<p>The interpretation of the <span class="math inline">\(RMSE\)</span> and <span class="math inline">\(\bar{R}^2\)</span> remains the same. Hypotheses are setup for each independent variable as usual. Generating predicted values requires some work though because you have to set each independent variable to a specific value when generating <span class="math inline">\(\hat{y}\)</span>. We typically start by setting all independent variables to their mean (or median) value (if the independent variable is numeric) and to their modal values (if the independent variable is categorical). Let us anchor our grasp of these in the context of a specific problem.</p>
<div id="two-numeric-i.e.-continuous-independent-variables" class="section level3 hasAnchor" number="12.3.1">
<h3><span class="header-section-number">12.3.1</span> Two Numeric (i.e., Continuous) Independent Variables<a href="linreg.html#two-numeric-i.e.-continuous-independent-variables" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Say we are interested in studying the impact of two continuous independent variables, <em>education</em> and <em>experience</em>, on <em>wage</em>, i.e., <span class="math inline">\(\hat{y} = \hat{a} + \hat{b}_1\left( education \right) + \hat{b}_2\left( experience \right)\)</span>. When you fit this regression model the estimates will be as follows:</p>
<table style="border-collapse:collapse; border:none;">
<tr>
<th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; ">
 
</th>
<th colspan="8" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
wage
</th>
</tr>
<tr>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; ">
Predictors
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
std. Error
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
std. Beta
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
standardized std. Error
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col7">
standardized CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col8">
Statistic
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col9">
p
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
(Intercept)
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-385.08
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
13.24
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.00
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.01
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-411.04 – -359.13
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
-0.01 – 0.01
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
-29.08
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
education
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
60.90
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.88
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.39
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.01
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
59.17 – 62.63
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
0.38 – 0.40
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
68.98
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
experience
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
10.61
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.20
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.31
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.01
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
10.22 – 10.99
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
0.29 – 0.32
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
54.19
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;">
Observations
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="8">
28155
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
R<sup>2</sup> / R<sup>2</sup> adjusted
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="8">
0.177 / 0.177
</td>
</tr>
</table>
<ul>
<li>The intercept is statistically significant and is <span class="math inline">\(\hat{a} = -385.0834\)</span>, indicating that when both education and experience are <span class="math inline">\(=0\)</span>, predicted wage is <span class="math inline">\(-385.0834\)</span>. Note that this makes no substantive sense but we are not interested in interpreting the intercept per se.</li>
<li>The partial slope on <em>education</em> is statistically significant and is <span class="math inline">\(\hat{b}_1 = 60.8964\)</span>, indicating that holding <em>experience</em> constant, for every one more year of <em>education</em> <em>wage</em> increases by $60.8964.</li>
<li>The partial slope on <em>experience</em> is statistically significant and is <span class="math inline">\(\hat{b}_2 = 10.6057\)</span>, indicating that holding <em>education</em> constant, for every one more year of <em>experience</em> <em>wage</em> increases by $10.6057.</li>
<li><span class="math inline">\(RMSE = 411.5\)</span>, indicating that average prediction error from this regression model would be <span class="math inline">\(\pm 411.5\)</span></li>
<li>The <span class="math inline">\(\bar{R}^2 = 0.1768\)</span> indicating that about <span class="math inline">\(17.68\%\)</span> of the variation in <em>wage</em> is explained by this regression model.</li>
</ul>
<p>What about predicted values? Let us calculate a few.</p>
<ol style="list-style-type: lower-alpha">
<li>Predict wage when education is at its mean and experience is at its mean:</li>
</ol>
<p><span class="math display">\[\begin{array}{l}
= -385.0834 + 60.8964(education) + 10.6057(experience) \\
= -385.0834 + 60.8964(13.06787) + 10.6057(18.19993) \\
= -385.0834 + 795.7862 + 193.023 = 603.7258
\end{array}\]</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Predict wage when education is at its mean and experience is (i) <span class="math inline">\(8\)</span>, and (ii) <span class="math inline">\(27\)</span>:</li>
</ol>
<p><span class="math display">\[\begin{array}{l}
= -385.0834 + 60.8964(13.06787) + 10.6057(8) \\
= -385.0834 + 795.7862 + 84.8456 = 495.5484
\end{array}\]</span></p>
<p><span class="math display">\[\begin{array}{l}
= -385.0834 + 60.8964(13.06787) + 10.6057(27) \\
= -385.0834 + 795.7862 + 286.3539 = 697.0567
\end{array}\]</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Predict wage when experience is at its mean and education is (i) <span class="math inline">\(12\)</span>, and (ii) <span class="math inline">\(15\)</span>:</li>
</ol>
<p><span class="math display">\[\begin{array}{l}
= -385.0834 + 60.8964(12) + 10.6057(18.19993) \\
= -385.0834 + 730.7568 + 193.023 = 538.6964
\end{array}\]</span></p>
<p><span class="math display">\[\begin{array}{l}
= -385.0834 + 60.8964(15) + 10.6057(18.19993) \\
= -385.0834 + 913.446 + 193.023 = 721.3856
\end{array}\]</span></p>
</div>
<div id="one-numeric-and-one-categorical-independent-variable" class="section level3 hasAnchor" number="12.3.2">
<h3><span class="header-section-number">12.3.2</span> One Numeric and One Categorical Independent Variable<a href="linreg.html#one-numeric-and-one-categorical-independent-variable" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let us stay with <em>education</em> as the continuous independent variable but add a categorical independent variable – <em>parttime</em> – that tells us whether the individual was working full-time <span class="math inline">\((parttime = 0)\)</span> or not <span class="math inline">\((parttime = 1)\)</span>. The regression model is:</p>
<p><span class="math display">\[wage = \hat{\alpha} + \hat{\beta_1}(education) + \hat{\beta_2}(parttime) + e\]</span></p>
<table style="border-collapse:collapse; border:none;">
<tr>
<th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; ">
 
</th>
<th colspan="8" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
wage
</th>
</tr>
<tr>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; ">
Predictors
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
std. Error
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
std. Beta
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
standardized std. Error
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col7">
standardized CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col8">
Statistic
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col9">
p
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
(Intercept)
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
27.99
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
11.50
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.08
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.01
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
5.44 – 50.54
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
0.07 – 0.09
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
2.43
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
<strong>0.015</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
education
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
46.82
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.86
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.30
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.01
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
45.14 – 48.49
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
0.29 – 0.31
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
54.63
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
parttime [yes]
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-402.05
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
8.70
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.89
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.02
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-419.10 – -385.00
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
-0.92 – -0.85
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
-46.22
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;">
Observations
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="8">
28155
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
R<sup>2</sup> / R<sup>2</sup> adjusted
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="8">
0.155 / 0.155
</td>
</tr>
</table>
<p>As estimated, the model turns out to be:</p>
<p><span class="math display">\[wage = 27.9930 + 46.8153(education) - 402.0493(parttime)\]</span></p>
<p>and this regression equation makes clear that the estimate of <span class="math inline">\(-402.0493\)</span> applies to the case of a part-time employee. What would predicted values look like for part-time versus full-time employees, for specific values of education.</p>
<ul>
<li>For a part-time employee, predicted wage is <span class="math inline">\(= 27.9930 + 46.8153(education) - 402.0493(1) = -374.0563 + 46.8153(education)\)</span></li>
<li>For a full-time employee, predicted wage is <span class="math inline">\(= 27.9930 + 46.8153(education) - 402.0493(0) = 27.9930 + 46.8153(education)\)</span></li>
</ul>
<p>So quite clearly, holding all else constant, on average, part-time employees make <span class="math inline">\(402.0493\)</span> less than full-time employees. For every one more year of education, wage increases by <span class="math inline">\(46.8153\)</span>. When <span class="math inline">\(education = 0\)</span> and the employee is a full-time employee, predicted wage is <span class="math inline">\(27.9930\)</span>.</p>
<p>Now we switch things up by fitting a regression model that predicts wage on the basis of two categorical variables. We have already worked with <em>parttime</em> so let us add the second categorical variable, <em>region</em>. The resulting regression model is:</p>
<p><span class="math display">\[wage = \hat{\alpha} + \hat{\beta_1}(parttime) + \hat{\beta_2}(region) + e\]</span></p>
<p>When you estimate the model you will see the following results:</p>
<table style="border-collapse:collapse; border:none;">
<tr>
<th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; ">
 
</th>
<th colspan="8" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
wage
</th>
</tr>
<tr>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; ">
Predictors
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
std. Error
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
std. Beta
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
standardized std. Error
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col7">
standardized CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col8">
Statistic
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col9">
p
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
(Intercept)
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
593.92
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
4.74
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.02
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.01
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
584.63 – 603.21
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
-0.04 – -0.00
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
125.34
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
parttime [yes]
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-405.68
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
9.12
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.89
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.02
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-423.57 – -387.80
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
-0.93 – -0.86
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
-44.47
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
region [northeast]
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
91.11
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
7.18
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.20
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.02
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
77.04 – 105.17
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
0.17 – 0.23
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
12.70
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
region [midwest]
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
48.41
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
7.05
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.11
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.02
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
34.60 – 62.22
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
0.08 – 0.14
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
6.87
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
region [west]
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
62.54
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
7.29
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.14
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.02
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
48.25 – 76.84
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
0.11 – 0.17
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
8.58
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;">
Observations
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="8">
28155
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
R<sup>2</sup> / R<sup>2</sup> adjusted
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="8">
0.071 / 0.071
</td>
</tr>
</table>
<p>that then lead to the following regression equation:</p>
<p><span class="math display">\[wage = 593.921 - 405.684(parttime = yes) + 91.106(region = northeast) + 48.412(region = midwest) + 62.544(region = west)\]</span></p>
<p>The correct starting point would be to see what the <em>Intercept</em> represents. Since we see a partial slope for <em>parttime = yes</em> the <em>Intercept</em> must be absorbing <em>parttime = no</em>, and the omitted <em>region = south</em>. That is, the <em>Intercept</em> is yielding the predicted wage <span class="math inline">\((593.921)\)</span> when the individual is a full-time employee who lives in the South. Let us spell out this situation and all other possibilities as well.</p>
<ul>
<li>Full-time living in the South: <span class="math inline">\(wage = 593.921\)</span></li>
<li>Full-time living in the Northeast: <span class="math inline">\(wage = 593.921 + 91.106 = 685.027\)</span><br />
</li>
<li>Full-time living in the Midwest: <span class="math inline">\(wage = 593.921 + 48.412 = 642.333\)</span><br />
</li>
<li>Full-time living in the West: <span class="math inline">\(wage = 593.921 + 62.544 = 656.465\)</span><br />
</li>
<li>Part-time living in the South: <span class="math inline">\(wage = 593.921 - 405.684 = 188.237\)</span></li>
<li>Full-time living in the Northeast: <span class="math inline">\(wage = 593.921 + 91.106  - 405.684 = 279.343\)</span><br />
</li>
<li>Full-time living in the Midwest: <span class="math inline">\(wage = 593.921 + 48.412 - 405.684 = 236.649\)</span><br />
</li>
<li>Full-time living in the West: <span class="math inline">\(wage = 593.921 + 62.544 - 405.684 = 250.781\)</span></li>
</ul>
</div>
<div id="interaction-effects-1" class="section level3 hasAnchor" number="12.3.3">
<h3><span class="header-section-number">12.3.3</span> Interaction Effects<a href="linreg.html#interaction-effects-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Say we are back in the world of the regression model with <em>education</em> and <em>parttime</em>. When we fit this model before, we saw a constant difference in <em>predicted wage</em> for the employee’s full-time/part-time status. In particular, we saw predicted wage being lower by a constant amount for every level of education. However, what if part-time/full-time status has more of an impact on wage at low education levels than it does at high education levels? This is quite likely to be true if, once you have sufficient education, part-time status does not depress your wage as much as it does when you have low educational attainment. Situations such as these are referred to as <code>interaction effects</code>. In general, An interaction effect exists when the magnitude of the effect of one independent variable <span class="math inline">\((x_1)\)</span> on a dependent variable <span class="math inline">\((y)\)</span> varies as a function of a second independent variable <span class="math inline">\((x_2)\)</span>. Models such as these are written as follows:</p>
<p><span class="math display">\[wage = \hat{\alpha} + \hat{\beta_1}(education) + \hat{\beta_2}(parttime) + \hat{\beta_3}(education \times parttime) + e\]</span></p>
<p>Now, we may either have <em>a priori</em> expectations of an interaction effect or just be looking to see if an interaction effect exists. Regardless, if we were to fit such a model to the data, we would see the following:</p>
<table style="border-collapse:collapse; border:none;">
<tr>
<th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; ">
 
</th>
<th colspan="10" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
wage
</th>
</tr>
<tr>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; ">
Predictors
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
std. Error
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
std. Beta
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
standardized std. Error
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col7">
standardized CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col8">
Statistic
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col9">
std. Statistic
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  0">
p
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  1">
std. p
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
(Intercept)
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-19.07
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
11.97
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.08
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.01
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-42.53 – 4.39
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
0.07 – 0.09
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
-1.59
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
13.87
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  0">
0.111
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  1">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
education
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
50.41
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.89
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.32
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.01
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
48.66 – 52.17
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
0.31 – 0.33
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
56.41
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
56.41
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  0">
<strong>&lt;0.001</strong>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  1">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
parttime [yes]
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
137.35
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
40.38
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.89
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.02
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
58.21 – 216.49
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
-0.93 – -0.86
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
3.40
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
-46.73
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  0">
<strong>0.001</strong>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  1">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
education × parttime<br>[yes]
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-41.52
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
3.04
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.27
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.02
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-47.47 – -35.57
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
-0.30 – -0.23
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
-13.68
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
-13.68
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  0">
<strong>&lt;0.001</strong>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  1">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;">
Observations
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="10">
28155
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
R<sup>2</sup> / R<sup>2</sup> adjusted
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="10">
0.161 / 0.161
</td>
</tr>
</table>
<p>Note the estimated regression line:</p>
<p><span class="math display">\[wage = - 19.0698 + 50.4144(education) + 137.3511(parttime) - 41.5221(education \times parttime)\]</span></p>
<p>For a model such as this, we speak of two types of effects – (a) a <code>main effect</code> of an independent variable, and an (b) <code>interaction effect</code> for each variable. These effects are best understood visually, and then through a series of calculations that will underline what is going on in the model.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:interactions"></span>
<img src="_stats_files/figure-html/interactions-1.svg" alt="Interaction between parttime and education" width="60%" />
<p class="caption">
FIGURE 12.16: Interaction between parttime and education
</p>
</div>
<p>You see two regression lines, one for part-time employees and the other for full-time employees, each drawn for specific values of education. At low education levels, full-time employees <span class="math inline">\((parttime = no)\)</span> have a lower average wage than do part-time employees <span class="math inline">\((parttime = yes)\)</span>. At a certain education level there seems to be no difference at all, roughly around <span class="math inline">\(education = 3\)</span>. Once the employee has 4 or more years of education, however, the gap in wages increases in favor of full-time employees for each additional year of education. This widening gap is clearly visible in the steepening regression line for <span class="math inline">\(parttime = no\)</span> at higher education levels. We could also calculate predicted wage when <span class="math inline">\(education = 0\)</span>, and then for <span class="math inline">\(education = 3\)</span>, and then for <span class="math inline">\(education = 18\)</span> to see the gap in action. Let us do so now.</p>
<ul>
<li>For a part-time employee with <span class="math inline">\(0\)</span> years of education, the predicted wage is</li>
</ul>
<p><span class="math display">\[\begin{array}{l}
wage = - 19.0698  + 50.4144(education = 0) + 137.3511(parttime = 1) - 41.5221(0 \times 1) \\
= - 19.0698  + 50.4144(0) + 137.3511(1) - 41.5221(0) \\
= - 19.0698  + 137.3511 \\
= 118.2813
\end{array}\]</span></p>
<ul>
<li>For a full-time employee with <span class="math inline">\(0\)</span> years of education, the predicted wage is</li>
</ul>
<p><span class="math display">\[\begin{array}{l}
wage = - 19.0698 + 50.4144(education = 0) + 137.3511(parttime = 0) - 41.5221(0 \times 0) \\
= - 19.0698
\end{array}\]</span></p>
<p>Repeating the preceding calculations for <span class="math inline">\(education = 3\)</span> will yield predicted wages of <span class="math inline">\(144.9582\)</span> for part-time employees and <span class="math inline">\(132.1733\)</span> for full-time employees. When education = <span class="math inline">\(4\)</span>, full-time employees are predicted to have a wage of <span class="math inline">\(182.5877\)</span> and part-time employees a wage of <span class="math inline">\(153.8505\)</span>. When education is at it’s maximum in-sample value of <span class="math inline">\(18\)</span>, predicted wages are <span class="math inline">\(278.3428\)</span> for part-time employees and <span class="math inline">\(888.3890\)</span> for full-time employees. Let us toss these into a table to ease the narrative.</p>
<table class="table table-striped" style="font-size: 12px; width: auto !important; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:predtab">TABLE 12.5: </span>Predicted wages from the interaction model
</caption>
<thead>
<tr>
<th style="text-align:right;">
Education
</th>
<th style="text-align:right;">
Part-time Wage
</th>
<th style="text-align:right;">
Full-time Wage
</th>
<th style="text-align:right;">
Wage Differential
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
118.28
</td>
<td style="text-align:right;">
-19.07
</td>
<td style="text-align:right;">
137.35
</td>
</tr>
<tr>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
144.96
</td>
<td style="text-align:right;">
132.17
</td>
<td style="text-align:right;">
12.78
</td>
</tr>
<tr>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
153.85
</td>
<td style="text-align:right;">
182.59
</td>
<td style="text-align:right;">
-28.74
</td>
</tr>
<tr>
<td style="text-align:right;">
18
</td>
<td style="text-align:right;">
278.34
</td>
<td style="text-align:right;">
888.39
</td>
<td style="text-align:right;">
-610.05
</td>
</tr>
</tbody>
</table>
<p>Evidently, then, the impact of part-time versus full-time status is not constant across education levels but in fact varies by education level: Education and employment status interact to influence an employee’s wage.</p>
<p>I mentioned this earlier but it bears repeating. First, either we expect an interaction between some variables because theory or past research tells us an interaction effect should exist, or if there is nothing to go by we ourselves might wish to test for an interaction. Second, whether an estimated coefficient is statistically significant or not has consequences for how we interpret the model and how we generate predicted values. For predicted values we use all estimated coefficients, even if some of them are not statistically significant. However, for interpretation we only focus on statistically significant estimates. The example below walks you through these conditions.</p>
<p>The data we will work with is an extract from the Current Population Survey (1985). Several attributes are measured for individual; the details follow.</p>
<ul>
<li>wage = wage (US dollars per hour)</li>
<li>educ = number of years of education</li>
<li>race = a factor with levels NW (nonwhite) or W (white)</li>
<li>sex = a factor with levels F M</li>
<li>hispanic = a factor with levels Hisp NH</li>
<li>south = a factor with levels NS S</li>
<li>married = a factor with levels Married Single</li>
<li>exper = number of years of work experience (inferred from age and educ)</li>
<li>union = a factor with levels Not Union</li>
<li>age = age in years</li>
<li>sector = a factor with levels clerical const manag manuf other prof sales service</li>
</ul>
<p>Assume we know nothing about what influences wage but we suspect the wage is influenced by experience. Let us also say that we suspect women earn less than men. We do not know if there is an interaction between education and sex. In fact, our research team is split where one group thinks there is no interaction. The other groups feels strongly that an interaction might exist. So we fit two models, one to appease the no interaction group and the other to appease the interaction group. The results are shown below:</p>
<table style="border-collapse:collapse; border:none;">
<tr>
<th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; ">
 
</th>
<th colspan="8" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
wage
</th>
</tr>
<tr>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; ">
Predictors
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
std. Error
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
std. Beta
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
standardized std. Error
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col7">
standardized CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col8">
Statistic
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col9">
p
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
(Intercept)
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
7.07
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.46
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.23
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.06
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
6.17 – 7.98
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
-0.35 – -0.11
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
15.36
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
exper
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.04
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.02
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.10
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.04
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.01 – 0.08
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
0.02 – 0.19
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
2.43
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
<strong>0.015</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
sex [M]
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
2.20
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.44
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.43
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.08
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.34 – 3.05
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
0.26 – 0.59
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
5.03
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;">
Observations
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="8">
534
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
R<sup>2</sup> / R<sup>2</sup> adjusted
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="8">
0.053 / 0.049
</td>
</tr>
</table>
<p>These results are for the <code>no interaction model</code>. Note the essential message here: average wage increases with experience, and males earn, on average, more than women, for the same level of experience. So what is being inferred here is that the <code>slope is the same</code> for both men and women; they differ only in the sense of a constant wage differential.</p>
<p>We then re-estimate the model to soothe the <code>with interaction group</code>. When we do so, we see the following results:</p>
<table style="border-collapse:collapse; border:none;">
<tr>
<th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; ">
 
</th>
<th colspan="10" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
wage
</th>
</tr>
<tr>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; ">
Predictors
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
std. Error
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
std. Beta
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
standardized std. Error
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col7">
standardized CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col8">
Statistic
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col9">
std. Statistic
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  0">
p
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  1">
std. p
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
(Intercept)
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
7.86
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.57
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.22
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.06
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
6.73 – 8.98
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
-0.35 – -0.10
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
13.69
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
-3.58
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  0">
<strong>&lt;0.001</strong>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  1">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
exper
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.00
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.03
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.00
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.06
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.05 – 0.05
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
-0.12 – 0.12
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
0.05
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
0.05
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  0">
0.964
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  1">
0.964
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
sex [M]
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.76
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.76
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.43
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.08
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.74 – 2.27
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
0.26 – 0.59
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
1.00
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
5.03
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  0">
0.318
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  1">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
exper × sex [M]
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.08
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.04
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.19
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.08
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.01 – 0.15
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
0.03 – 0.36
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
2.27
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
2.27
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  0">
<strong>0.023</strong>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  1">
<strong>0.023</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;">
Observations
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="10">
534
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
R<sup>2</sup> / R<sup>2</sup> adjusted
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="10">
0.062 / 0.057
</td>
</tr>
</table>
<p>Note what these results tell us. First, neither experience nor sex matter on their own; the p-values are way above <span class="math inline">\(0.05\)</span> so on it’s own neither variable influences wage. However, the interaction is significant. What this is telling us is that while neither variable shapes wage on its own, the two interact to do so! The interaction is clearly visible in the plot below:</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:interactionsa"></span>
<img src="_stats_files/figure-html/interactionsa-1.svg" alt="No Interaction Model" width="60%" />
<p class="caption">
FIGURE 12.17: No Interaction Model
</p>
</div>
<p>Note the differing slopes, with the regression line for Males being steeper than that for the Females.</p>
<p>So which set of results do we believe? Well, you are in a bind. If you started out on the side of the no interaction group and then saw the results for the interaction group, you would second-guess yourself and perhaps admit that you were wrong; there is an interaction. That would be the appropriate response. What would be unacceptable is for you to brush off the results from the model with an interaction and instead stick with your no interaction model.</p>
<p>But what if the interaction were not significant, as in the case below? Which model would be preferable then?</p>
<table style="border-collapse:collapse; border:none;">
<tr>
<th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; ">
 
</th>
<th colspan="8" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
wage
</th>
<th colspan="10" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
wage
</th>
</tr>
<tr>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; ">
Predictors
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
std. Error
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
std. Beta
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
standardized std. Error
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col7">
standardized CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col8">
Statistic
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col9">
p
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  0">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  1">
std. Error
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  2">
std. Beta
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  3">
standardized std. Error
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  4">
CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  5">
standardized CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  6">
Statistic
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  7">
std. Statistic
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  8">
p
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  9">
std. p
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
(Intercept)
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-1.91
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.04
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.22
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.06
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-3.96 – 0.14
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
-0.34 – -0.11
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
-1.83
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
0.068
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  0">
-3.27
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  1">
1.62
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  2">
-0.22
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  3">
0.06
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  4">
-6.45 – -0.09
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  5">
-0.34 – -0.11
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  6">
-2.02
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  7">
-3.88
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  8">
<strong>0.044</strong>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  9">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
educ
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.75
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.08
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.38
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.04
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.60 – 0.90
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
0.31 – 0.46
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
9.78
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
<strong>&lt;0.001</strong>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  0">
0.86
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  1">
0.12
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  2">
0.44
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  3">
0.06
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  4">
0.62 – 1.10
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  5">
0.31 – 0.56
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  6">
7.00
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  7">
7.00
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  8">
<strong>&lt;0.001</strong>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  9">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
sex [M]
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
2.12
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.40
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.41
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.08
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.33 – 2.92
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
0.26 – 0.57
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
5.27
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
<strong>&lt;0.001</strong>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  0">
4.37
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  1">
2.09
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  2">
0.41
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  3">
0.08
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  4">
0.27 – 8.47
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  5">
0.26 – 0.57
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  6">
2.10
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  7">
5.27
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  8">
<strong>0.037</strong>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  9">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
educ × sex [M]
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  0">
-0.17
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  1">
0.16
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  2">
-0.09
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  3">
0.08
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  4">
-0.48 – 0.14
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  5">
-0.24 – 0.07
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  6">
-1.10
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  7">
-1.10
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  8">
0.273
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  9">
0.273
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;">
Observations
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="8">
534
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="10">
534
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
R<sup>2</sup> / R<sup>2</sup> adjusted
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="8">
0.188 / 0.185
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="10">
0.190 / 0.186
</td>
</tr>
</table>
<p>Now, note that the interaction is not statistically significant; the p-value is <span class="math inline">\(0.2727\)</span>, way above <span class="math inline">\(0.05\)</span>. If the interaction is not statistically significant, then you should opt for the model without an interaction because it is the simpler model – the priceless value of the principle of <code>Occam's Razor</code>: “When you have two competing theories that make exactly the same predictions, the simpler one is the better.” In the present situation that would mean defaulting to the model without an interaction.</p>
<p>What about interactions between two continuous variables? Those types of models require more effort, as shown below.</p>
<table style="border-collapse:collapse; border:none;">
<tr>
<th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; ">
 
</th>
<th colspan="10" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
wage
</th>
</tr>
<tr>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; ">
Predictors
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
std. Error
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
std. Beta
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
standardized std. Error
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col7">
standardized CI
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col8">
Statistic
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col9">
std. Statistic
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  0">
p
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  1">
std. p
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
(Intercept)
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-12.19
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.79
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.11
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.05
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-15.71 – -8.68
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
0.00 – 0.21
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
-6.82
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
2.04
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  0">
<strong>&lt;0.001</strong>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  1">
<strong>0.042</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
exper
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.61
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.10
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-1.82
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.19
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.82 – -0.41
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
-2.20 – -1.44
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
-5.84
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
-9.51
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  0">
<strong>&lt;0.001</strong>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  1">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
age
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.96
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.08
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
2.02
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.19
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.80 – 1.12
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
1.66 – 2.39
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
11.72
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
10.84
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  0">
<strong>&lt;0.001</strong>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  1">
<strong>&lt;0.001</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
exper × age
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.00
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.00
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.11
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.04
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.01 – -0.00
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
-0.19 – -0.04
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
-2.94
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
-2.94
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  0">
<strong>0.003</strong>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  1">
<strong>0.003</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;">
Observations
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="10">
534
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
R<sup>2</sup> / R<sup>2</sup> adjusted
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="10">
0.214 / 0.209
</td>
</tr>
</table>
<p>Note that both experience and age each influence wage, but they also interact for added influence. The only way to figure out what this model is telling us would be by way of predicted values, allowing one variable to change by a specific amount while the other variable is held fixed at a specific values. Common practice is to set the independent variable to be held constant to the mean, and then to 1 standard deviation above the mean and 1 standard deviation below the mean. Alternatively, some analysts will set it to the median value, and then to the first quartile <span class="math inline">\((Q_1)\)</span> and then to the third quartile <span class="math inline">\((Q_3)\)</span>. Here is a simple table that lists these values for each independent variable.</p>
<table class="table table-striped" style="font-size: 12px; width: auto !important; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:intertables">TABLE 12.6: </span>Summary Statistics of the Two Independent Variables
</caption>
<thead>
<tr>
<th style="text-align:left;">
Variable
</th>
<th style="text-align:right;">
Mean
</th>
<th style="text-align:right;">
SD
</th>
<th style="text-align:right;">
Median
</th>
<th style="text-align:right;">
Q1
</th>
<th style="text-align:right;">
Q3
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
exper
</td>
<td style="text-align:right;">
17.82
</td>
<td style="text-align:right;">
12.38
</td>
<td style="text-align:right;">
15
</td>
<td style="text-align:right;">
8
</td>
<td style="text-align:right;">
26
</td>
</tr>
<tr>
<td style="text-align:left;">
age
</td>
<td style="text-align:right;">
36.83
</td>
<td style="text-align:right;">
11.73
</td>
<td style="text-align:right;">
35
</td>
<td style="text-align:right;">
28
</td>
<td style="text-align:right;">
44
</td>
</tr>
</tbody>
</table>
<p>Now, let us calculate and plot the predicted values holding <code>exper</code> fixed to each value and allowing <code>age</code> to vary.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:continvisreg"></span>
<img src="_stats_files/figure-html/continvisreg-1.svg" alt="Holding exper at Median and Quartiles vs. Mean and unit Standard Deviations" width="60%" /><img src="_stats_files/figure-html/continvisreg-2.svg" alt="Holding exper at Median and Quartiles vs. Mean and unit Standard Deviations" width="60%" />
<p class="caption">
FIGURE 12.18: Holding exper at Median and Quartiles vs. Mean and unit Standard Deviations
</p>
</div>
<p>and then allowing <code>exper</code> to vary while setting <code>age</code> to specific values.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:continvisreg2"></span>
<img src="_stats_files/figure-html/continvisreg2-1.svg" alt="Holding age at Median and Quartiles vs. Mean and unit Standard Deviations" width="60%" /><img src="_stats_files/figure-html/continvisreg2-2.svg" alt="Holding age at Median and Quartiles vs. Mean and unit Standard Deviations" width="60%" />
<p class="caption">
FIGURE 12.19: Holding age at Median and Quartiles vs. Mean and unit Standard Deviations
</p>
</div>
</div>
</div>
<div id="assumptions-of-linear-regression" class="section level2 hasAnchor" number="12.4">
<h2><span class="header-section-number">12.4</span> Assumptions of Linear Regression<a href="linreg.html#assumptions-of-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The Classical Linear Regression Model (CLRM) is built upon the following assumptions, though some of these are assumed to be true prior to any data analysis being initiated.</p>
<ol style="list-style-type: decimal">
<li>The regression model is linear in terms of <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span></li>
<li>The values of <span class="math inline">\(x\)</span> are fixed in repeated sampling</li>
<li>Zero mean value of the residuals, i.e., <span class="math inline">\(E(e_i | x_i) = 0\)</span></li>
<li>Homoscedasticity, i.e., the residuals have a constant variance for each <span class="math inline">\(x_i\)</span>, that is <span class="math inline">\(var(e_i|x_i = \sigma^2)\)</span><br />
</li>
<li>No autocorrelation or serial correlation between the disturbances, i.e., <span class="math inline">\(cov(e_i e_j | x_i x_j = 0)\)</span></li>
<li>Zero covariance between <span class="math inline">\(e_i\)</span> and <span class="math inline">\(x_i\)</span> i.e., <span class="math inline">\(E(e_i x_i = 0)\)</span></li>
<li>The number of observations exceeds the number of parameters to be estimated</li>
<li>Variability in <span class="math inline">\(x\)</span> values</li>
<li>The regression model is correctly specified</li>
<li>There is no perfect multicollinearity</li>
</ol>
<div id="assumption-1-linear-regression-model" class="section level3 hasAnchor" number="12.4.1">
<h3><span class="header-section-number">12.4.1</span> Assumption 1: Linear Regression Model<a href="linreg.html#assumption-1-linear-regression-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The regression model is assumedly <code>linear in parameters</code>. That is, a function is said to be linear in <span class="math inline">\(x\)</span> if the value of the change in <span class="math inline">\(y\)</span> does not depend upon the value of <span class="math inline">\(x\)</span> when <span class="math inline">\(x\)</span> changes by a unit. Thus if <span class="math inline">\(y = 4x\)</span>, <span class="math inline">\(y\)</span> changes by <span class="math inline">\(4\)</span> for every unit change in <span class="math inline">\(x\)</span>, regardless of whether <span class="math inline">\(x\)</span> changes from <span class="math inline">\(1\)</span> to <span class="math inline">\(2\)</span> or from <span class="math inline">\(19\)</span> to <span class="math inline">\(20\)</span>. But if <span class="math inline">\(y=4x^2\)</span>, then when <span class="math inline">\(x=1\)</span>, <span class="math inline">\(y=4(1^1) = 4\)</span> and when <span class="math inline">\(x\)</span> increases by a unit to <span class="math inline">\(x=2\)</span>, we have <span class="math inline">\(y=4(2^2) = 16\)</span>. When <span class="math inline">\(x\)</span> increase by another unit, <span class="math inline">\(y=4(3^2) = 36\)</span> <span class="math inline">\(\ldots\)</span> note that the value <span class="math inline">\(y\)</span> assumes is now dependent upon what <span class="math inline">\(x\)</span> was when it increased (or decreased) by <span class="math inline">\(1\)</span>. In sum, a function <span class="math inline">\(y = \beta(x)\)</span> is linear in parameters if the coefficient <span class="math inline">\(\beta\)</span> appears with a power of <span class="math inline">\(1\)</span>. In this sense, <span class="math inline">\(y=\beta(x^2)\)</span> is linear in parameters, as is <span class="math inline">\(y=\beta(\sqrt{x})\)</span>. In the regression framework, then, <span class="math inline">\(y = \alpha + \beta_1x + \beta_2x^2\)</span>, <span class="math inline">\(y=\alpha + \beta_1x + \beta_2x^2 + \beta_3x^3\)</span> and so on are all <code>linear in parameters</code> but not so regressions such as <span class="math inline">\(y = \alpha + \beta_1^2x + \beta_2x^2\)</span> or <span class="math inline">\(y = \alpha + \beta_1^{1/3}x + \beta_2x^2\)</span>, etc.</p>
</div>
<div id="assumption-2-x-values-fixed-in-repeated-sampling" class="section level3 hasAnchor" number="12.4.2">
<h3><span class="header-section-number">12.4.2</span> Assumption 2: <span class="math inline">\(x\)</span> values fixed in repeated sampling<a href="linreg.html#assumption-2-x-values-fixed-in-repeated-sampling" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>For every value of <span class="math inline">\(x\)</span> in the population, we have a range of <span class="math inline">\(y\)</span> values that are likely to be observed.
We are assuming that if we hold <span class="math inline">\(x\)</span> at a specific value and keep drawing repeated samples, we will end up with all possible values of <span class="math inline">\(y\)</span> for the fixed <span class="math inline">\(x\)</span> value. This will allow us to estimate <span class="math inline">\(E(y)\)</span> given that <span class="math inline">\(x\)</span> is a specific value. But if we cannot be at all confident that we know the <code>conditional distribution of $y$ given $x$</code>, then we cannot predict what <span class="math inline">\(y\)</span> may be given <span class="math inline">\(x\)</span>. A technically accurate explanation is that in an experiment, the values of the independent variable would be fixed by the experimenter and repeated samples would be drawn with the independent variables fixed at the same values in each sample, resulting in the independent variable being uncorrelated with the residuals. Of course, we work with non-experimental data more often than not and hence we have to assume that the independent variables are fixed in repeated samples.</p>
</div>
<div id="assumption-3-zero-conditional-mean-value-of-residuals" class="section level3 hasAnchor" number="12.4.3">
<h3><span class="header-section-number">12.4.3</span> Assumption 3: Zero conditional mean value of Residuals<a href="linreg.html#assumption-3-zero-conditional-mean-value-of-residuals" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Formally, this assumption implies that <span class="math inline">\(E(e_i | x_i) = 0\)</span>, i.e., that given a specific <span class="math inline">\(x\)</span> value, the expected value of <span class="math inline">\(e\)</span> is <span class="math inline">\(0\)</span>. Recall that <span class="math inline">\(e\)</span> refers to the difference between actual and predicted <span class="math inline">\(y\)</span>. If you see the PRF in the plot, notice that the PRF passes through the middle of the <span class="math inline">\(y\)</span> values for each <span class="math inline">\(x\)</span> … or in other words, <span class="math inline">\(E(y | x_i)\)</span>. Look at the figure and table below and note that the regression line passes through the “middle” of the <span class="math inline">\(y\)</span> values for each <span class="math inline">\(x_i\)</span>, and that the residuals sum to zero for each <span class="math inline">\(x_i\)</span>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:assump3a"></span>
<img src="_stats_files/figure-html/assump3a-1.svg" alt="Regressing Expenditure on Income" width="60%" />
<p class="caption">
FIGURE 12.20: Regressing Expenditure on Income
</p>
</div>
<table class="table table-striped" style="font-size: 12px; width: auto !important; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:assump3b">TABLE 12.7: </span>Regressing Expenditure on Income
</caption>
<thead>
<tr>
<th style="text-align:right;">
Income
</th>
<th style="text-align:right;">
Actual Expenditure
</th>
<th style="text-align:right;">
Predicted Expenditure
</th>
<th style="text-align:right;">
Residuals
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
80
</td>
<td style="text-align:right;">
55
</td>
<td style="text-align:right;">
65
</td>
<td style="text-align:right;">
-10
</td>
</tr>
<tr>
<td style="text-align:right;">
80
</td>
<td style="text-align:right;">
60
</td>
<td style="text-align:right;">
65
</td>
<td style="text-align:right;">
-5
</td>
</tr>
<tr>
<td style="text-align:right;">
80
</td>
<td style="text-align:right;">
65
</td>
<td style="text-align:right;">
65
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:right;">
80
</td>
<td style="text-align:right;">
70
</td>
<td style="text-align:right;">
65
</td>
<td style="text-align:right;">
5
</td>
</tr>
<tr>
<td style="text-align:right;">
80
</td>
<td style="text-align:right;">
75
</td>
<td style="text-align:right;">
65
</td>
<td style="text-align:right;">
10
</td>
</tr>
<tr>
<td style="text-align:right;">
100
</td>
<td style="text-align:right;">
65
</td>
<td style="text-align:right;">
77
</td>
<td style="text-align:right;">
-12
</td>
</tr>
<tr>
<td style="text-align:right;">
100
</td>
<td style="text-align:right;">
70
</td>
<td style="text-align:right;">
77
</td>
<td style="text-align:right;">
-7
</td>
</tr>
<tr>
<td style="text-align:right;">
100
</td>
<td style="text-align:right;">
74
</td>
<td style="text-align:right;">
77
</td>
<td style="text-align:right;">
-3
</td>
</tr>
<tr>
<td style="text-align:right;">
100
</td>
<td style="text-align:right;">
80
</td>
<td style="text-align:right;">
77
</td>
<td style="text-align:right;">
3
</td>
</tr>
<tr>
<td style="text-align:right;">
100
</td>
<td style="text-align:right;">
85
</td>
<td style="text-align:right;">
77
</td>
<td style="text-align:right;">
8
</td>
</tr>
<tr>
<td style="text-align:right;">
100
</td>
<td style="text-align:right;">
88
</td>
<td style="text-align:right;">
77
</td>
<td style="text-align:right;">
11
</td>
</tr>
<tr>
<td style="text-align:right;">
120
</td>
<td style="text-align:right;">
79
</td>
<td style="text-align:right;">
89
</td>
<td style="text-align:right;">
-10
</td>
</tr>
<tr>
<td style="text-align:right;">
120
</td>
<td style="text-align:right;">
84
</td>
<td style="text-align:right;">
89
</td>
<td style="text-align:right;">
-5
</td>
</tr>
<tr>
<td style="text-align:right;">
120
</td>
<td style="text-align:right;">
90
</td>
<td style="text-align:right;">
89
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
120
</td>
<td style="text-align:right;">
94
</td>
<td style="text-align:right;">
89
</td>
<td style="text-align:right;">
5
</td>
</tr>
<tr>
<td style="text-align:right;">
120
</td>
<td style="text-align:right;">
98
</td>
<td style="text-align:right;">
89
</td>
<td style="text-align:right;">
9
</td>
</tr>
<tr>
<td style="text-align:right;">
140
</td>
<td style="text-align:right;">
80
</td>
<td style="text-align:right;">
101
</td>
<td style="text-align:right;">
-21
</td>
</tr>
<tr>
<td style="text-align:right;">
140
</td>
<td style="text-align:right;">
93
</td>
<td style="text-align:right;">
101
</td>
<td style="text-align:right;">
-8
</td>
</tr>
<tr>
<td style="text-align:right;">
140
</td>
<td style="text-align:right;">
95
</td>
<td style="text-align:right;">
101
</td>
<td style="text-align:right;">
-6
</td>
</tr>
<tr>
<td style="text-align:right;">
140
</td>
<td style="text-align:right;">
103
</td>
<td style="text-align:right;">
101
</td>
<td style="text-align:right;">
2
</td>
</tr>
<tr>
<td style="text-align:right;">
140
</td>
<td style="text-align:right;">
108
</td>
<td style="text-align:right;">
101
</td>
<td style="text-align:right;">
7
</td>
</tr>
<tr>
<td style="text-align:right;">
140
</td>
<td style="text-align:right;">
113
</td>
<td style="text-align:right;">
101
</td>
<td style="text-align:right;">
12
</td>
</tr>
<tr>
<td style="text-align:right;">
140
</td>
<td style="text-align:right;">
115
</td>
<td style="text-align:right;">
101
</td>
<td style="text-align:right;">
14
</td>
</tr>
<tr>
<td style="text-align:right;">
160
</td>
<td style="text-align:right;">
102
</td>
<td style="text-align:right;">
113
</td>
<td style="text-align:right;">
-11
</td>
</tr>
<tr>
<td style="text-align:right;">
160
</td>
<td style="text-align:right;">
107
</td>
<td style="text-align:right;">
113
</td>
<td style="text-align:right;">
-6
</td>
</tr>
<tr>
<td style="text-align:right;">
160
</td>
<td style="text-align:right;">
110
</td>
<td style="text-align:right;">
113
</td>
<td style="text-align:right;">
-3
</td>
</tr>
<tr>
<td style="text-align:right;">
160
</td>
<td style="text-align:right;">
116
</td>
<td style="text-align:right;">
113
</td>
<td style="text-align:right;">
3
</td>
</tr>
<tr>
<td style="text-align:right;">
160
</td>
<td style="text-align:right;">
118
</td>
<td style="text-align:right;">
113
</td>
<td style="text-align:right;">
5
</td>
</tr>
<tr>
<td style="text-align:right;">
160
</td>
<td style="text-align:right;">
125
</td>
<td style="text-align:right;">
113
</td>
<td style="text-align:right;">
12
</td>
</tr>
<tr>
<td style="text-align:right;">
180
</td>
<td style="text-align:right;">
110
</td>
<td style="text-align:right;">
125
</td>
<td style="text-align:right;">
-15
</td>
</tr>
<tr>
<td style="text-align:right;">
180
</td>
<td style="text-align:right;">
115
</td>
<td style="text-align:right;">
125
</td>
<td style="text-align:right;">
-10
</td>
</tr>
<tr>
<td style="text-align:right;">
180
</td>
<td style="text-align:right;">
120
</td>
<td style="text-align:right;">
125
</td>
<td style="text-align:right;">
-5
</td>
</tr>
<tr>
<td style="text-align:right;">
180
</td>
<td style="text-align:right;">
130
</td>
<td style="text-align:right;">
125
</td>
<td style="text-align:right;">
5
</td>
</tr>
<tr>
<td style="text-align:right;">
180
</td>
<td style="text-align:right;">
135
</td>
<td style="text-align:right;">
125
</td>
<td style="text-align:right;">
10
</td>
</tr>
<tr>
<td style="text-align:right;">
180
</td>
<td style="text-align:right;">
140
</td>
<td style="text-align:right;">
125
</td>
<td style="text-align:right;">
15
</td>
</tr>
<tr>
<td style="text-align:right;">
200
</td>
<td style="text-align:right;">
120
</td>
<td style="text-align:right;">
137
</td>
<td style="text-align:right;">
-17
</td>
</tr>
<tr>
<td style="text-align:right;">
200
</td>
<td style="text-align:right;">
136
</td>
<td style="text-align:right;">
137
</td>
<td style="text-align:right;">
-1
</td>
</tr>
<tr>
<td style="text-align:right;">
200
</td>
<td style="text-align:right;">
140
</td>
<td style="text-align:right;">
137
</td>
<td style="text-align:right;">
3
</td>
</tr>
<tr>
<td style="text-align:right;">
200
</td>
<td style="text-align:right;">
144
</td>
<td style="text-align:right;">
137
</td>
<td style="text-align:right;">
7
</td>
</tr>
<tr>
<td style="text-align:right;">
200
</td>
<td style="text-align:right;">
145
</td>
<td style="text-align:right;">
137
</td>
<td style="text-align:right;">
8
</td>
</tr>
<tr>
<td style="text-align:right;">
220
</td>
<td style="text-align:right;">
135
</td>
<td style="text-align:right;">
149
</td>
<td style="text-align:right;">
-14
</td>
</tr>
<tr>
<td style="text-align:right;">
220
</td>
<td style="text-align:right;">
137
</td>
<td style="text-align:right;">
149
</td>
<td style="text-align:right;">
-12
</td>
</tr>
<tr>
<td style="text-align:right;">
220
</td>
<td style="text-align:right;">
140
</td>
<td style="text-align:right;">
149
</td>
<td style="text-align:right;">
-9
</td>
</tr>
<tr>
<td style="text-align:right;">
220
</td>
<td style="text-align:right;">
152
</td>
<td style="text-align:right;">
149
</td>
<td style="text-align:right;">
3
</td>
</tr>
<tr>
<td style="text-align:right;">
220
</td>
<td style="text-align:right;">
157
</td>
<td style="text-align:right;">
149
</td>
<td style="text-align:right;">
8
</td>
</tr>
<tr>
<td style="text-align:right;">
220
</td>
<td style="text-align:right;">
160
</td>
<td style="text-align:right;">
149
</td>
<td style="text-align:right;">
11
</td>
</tr>
<tr>
<td style="text-align:right;">
220
</td>
<td style="text-align:right;">
162
</td>
<td style="text-align:right;">
149
</td>
<td style="text-align:right;">
13
</td>
</tr>
<tr>
<td style="text-align:right;">
240
</td>
<td style="text-align:right;">
137
</td>
<td style="text-align:right;">
161
</td>
<td style="text-align:right;">
-24
</td>
</tr>
<tr>
<td style="text-align:right;">
240
</td>
<td style="text-align:right;">
145
</td>
<td style="text-align:right;">
161
</td>
<td style="text-align:right;">
-16
</td>
</tr>
<tr>
<td style="text-align:right;">
240
</td>
<td style="text-align:right;">
155
</td>
<td style="text-align:right;">
161
</td>
<td style="text-align:right;">
-6
</td>
</tr>
<tr>
<td style="text-align:right;">
240
</td>
<td style="text-align:right;">
165
</td>
<td style="text-align:right;">
161
</td>
<td style="text-align:right;">
4
</td>
</tr>
<tr>
<td style="text-align:right;">
240
</td>
<td style="text-align:right;">
175
</td>
<td style="text-align:right;">
161
</td>
<td style="text-align:right;">
14
</td>
</tr>
<tr>
<td style="text-align:right;">
240
</td>
<td style="text-align:right;">
189
</td>
<td style="text-align:right;">
161
</td>
<td style="text-align:right;">
28
</td>
</tr>
<tr>
<td style="text-align:right;">
260
</td>
<td style="text-align:right;">
150
</td>
<td style="text-align:right;">
173
</td>
<td style="text-align:right;">
-23
</td>
</tr>
<tr>
<td style="text-align:right;">
260
</td>
<td style="text-align:right;">
152
</td>
<td style="text-align:right;">
173
</td>
<td style="text-align:right;">
-21
</td>
</tr>
<tr>
<td style="text-align:right;">
260
</td>
<td style="text-align:right;">
175
</td>
<td style="text-align:right;">
173
</td>
<td style="text-align:right;">
2
</td>
</tr>
<tr>
<td style="text-align:right;">
260
</td>
<td style="text-align:right;">
178
</td>
<td style="text-align:right;">
173
</td>
<td style="text-align:right;">
5
</td>
</tr>
<tr>
<td style="text-align:right;">
260
</td>
<td style="text-align:right;">
180
</td>
<td style="text-align:right;">
173
</td>
<td style="text-align:right;">
7
</td>
</tr>
<tr>
<td style="text-align:right;">
260
</td>
<td style="text-align:right;">
185
</td>
<td style="text-align:right;">
173
</td>
<td style="text-align:right;">
12
</td>
</tr>
<tr>
<td style="text-align:right;">
260
</td>
<td style="text-align:right;">
191
</td>
<td style="text-align:right;">
173
</td>
<td style="text-align:right;">
18
</td>
</tr>
</tbody>
</table>
<p>Look at the values of <span class="math inline">\(y\)</span> when <span class="math inline">\(x=80\)</span>. The mean of <span class="math inline">\(y\)</span> for <span class="math inline">\(x-80\)</span> is <span class="math inline">\(\bar{y}=65\)</span>. The gap between <span class="math inline">\(y_i\)</span> and <span class="math inline">\(\bar{y}\)</span> is <span class="math inline">\(-10, -5, 0, +5, +10\)</span> and when you add them, you get <span class="math inline">\(\sum (y_i - \bar{y}) | x_i=80 = 0\)</span>. Repeat this for <span class="math inline">\(x=260\)</span> … Note that the errors are <span class="math inline">\(-23, -21, 2, 5,   7, 12, 18\)</span> … and these add up to <span class="math inline">\(0\)</span>. So it must be that the regression line passes through <span class="math inline">\(\bar{y}\)</span> for each <span class="math inline">\(x\)</span> value.</p>
</div>
<div id="assumption-4-homoscedasticity" class="section level3 hasAnchor" number="12.4.4">
<h3><span class="header-section-number">12.4.4</span> Assumption 4: Homoscedasticity<a href="linreg.html#assumption-4-homoscedasticity" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Formally, <code>homoscedasticity</code> means that the conditional variance of the residuals <span class="math inline">\((e_i)\)</span> is constant across <span class="math inline">\(x_i\)</span>. That is, no matter what <span class="math inline">\(x\)</span> value we select, it should be that <span class="math inline">\(y\)</span> varies the same. A violation would be evident if, say, at <span class="math inline">\(x= 80\)</span> we see a lot of variance in <span class="math inline">\(y\)</span> but at <span class="math inline">\(x=160\)</span> we see minimal variance in <span class="math inline">\(y\)</span>. When might this happen? Imagine <span class="math inline">\(x\)</span> is income and <span class="math inline">\(y\)</span> is consumption expenditure. For low levels of income you are likely to see consumption varying narrowly. But as income rises, some people with the same income may consume quite a bit more or less than <code>others with the same income</code>. In such a case <span class="math inline">\(var(e_i|x_i \neq \sigma^2)\)</span> but rather <span class="math inline">\(var(e_i|x_i = \sigma^2_i)\)</span>. If homoscedasticity is violated we <code>heteroscedasticity</code>, and as a consequence the standard errors of the regression coefficients will be unreliable, which in turn means the significance tests and confidence intervals that use these standard errors will be unreliable as well.</p>
</div>
<div id="assumption-5-no-autocorrelation" class="section level3 hasAnchor" number="12.4.5">
<h3><span class="header-section-number">12.4.5</span> Assumption 5: No Autocorrelation<a href="linreg.html#assumption-5-no-autocorrelation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><code>Autocorrelation</code> (also referred to as <code>serial correlation</code>) occurs in time series data and with autocorrelated data <span class="math inline">\(cov(e_i e_j | x_i x_j \neq 0)\)</span>. This is a problem because now <span class="math inline">\(y\)</span> is also a function of <span class="math inline">\(e\)</span>, as shown below:</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:autocorr"></span>
<img src="images/autocorr.png" alt="Autocorrelation" width="60%" />
<p class="caption">
FIGURE 12.21: Autocorrelation
</p>
</div>
<p>In a cross-sectional data-set, this assumption becomes one of saying no two observations <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> are correlated by design. I emphasize “by design” because in a genuine random sample, each unit has been selected into the sample independently of all other units and consequently this assumption should, in theory, be met. However, some units may end up being correlated for reasons unknown to us.</p>
</div>
<div id="assumptions-6-7-and-8" class="section level3 hasAnchor" number="12.4.6">
<h3><span class="header-section-number">12.4.6</span> Assumptions 6, 7, and 8<a href="linreg.html#assumptions-6-7-and-8" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Assumption 6 requires zero Covariance between <span class="math inline">\(e\)</span> and <span class="math inline">\(x\)</span>. Formally, we need to have <span class="math inline">\(E(e_i x_i = 0)\)</span> and this is important because it allows us to reliably estimate the impact of a unit change in <span class="math inline">\(x\)</span> holding all else constant. If <span class="math inline">\(E(e_i x_i \neq 0)\)</span>, then whenever <span class="math inline">\(x\)</span> changes, so does <span class="math inline">\(e\)</span>. Think about this assumption as follows. In brief, the model we are fitting has been built by recognizing and measuring every independent variable known to influence <span class="math inline">\(y\)</span>. If we have forgotten to include some variables that do influence <span class="math inline">\(y\)</span>, these omitted variables will leak into the residuals (since the residuals represent all the variance of <span class="math inline">\(y\)</span> left unexplained by the model).</p>
<p>Assumption 7 requires that <span class="math inline">\(n\)</span> exceed the number of parameters to be estimated. Assume <span class="math inline">\(n=2\)</span>, can you estimate <span class="math inline">\(\hat{a}\)</span> and <span class="math inline">\(\hat{b}\)</span>? No you cannot because you will run into the degrees of freedom problem. So we always want to have a sufficiently large sample, and the more complex the regression model, the bigger the sample needed because each parameter that is estimated will use up a degree of freedom.</p>
<p>Assumption 8 requires variability in the <span class="math inline">\(x\)</span> values. Imagine if in a sample, all <span class="math inline">\(x_i = x\)</span>. Now <span class="math inline">\(\bar{x}=x\)</span>. What will happen to <span class="math inline">\(SS_x\)</span>? It will be <span class="math inline">\(0\)</span>, and no estimates will be calculable. Thus we require that the variance of <span class="math inline">\(x\)</span> be <span class="math inline">\(&gt; 0\)</span>. In other words, to calculate the effect of changes in <span class="math inline">\(x\)</span> on <span class="math inline">\(y\)</span>, the sample values <span class="math inline">\(x_i\)</span> of must vary across observations in any given sample.</p>
</div>
<div id="assumptions-9-and-10" class="section level3 hasAnchor" number="12.4.7">
<h3><span class="header-section-number">12.4.7</span> Assumptions 9 and 10<a href="linreg.html#assumptions-9-and-10" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Assumption 9 requires that the model is correctly specified. Modeling always begins with theory, and by drawing a good sample, measuring the right variables correctly, and so on. Assume the <code>TRUE MODEL</code> is <span class="math inline">\(y = a + b\left (\dfrac{1}{x} \right) + e\)</span> but we don’t know this and estimate <span class="math inline">\(y = a + bx + e\)</span>. Doing so will generate biased regression estimates! You can see this in the plot that follows, where for low values of <span class="math inline">\(x\)</span> we end up under-predicting <span class="math inline">\(y\)</span>, then over-predicting <span class="math inline">\(y\)</span> in the middle-range of <span class="math inline">\(x\)</span> values, and again under-predicting <span class="math inline">\(y\)</span> for high <span class="math inline">\(x\)</span> values.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:modspec"></span>
<embed src="images/Modelerror.pdf" title="Model Misspecification" width="60%" type="application/pdf" />
<p class="caption">
FIGURE 12.22: Model Misspecification
</p>
</div>
<p>Of course, we rarely know the true model and hence it is all the more important that you have a sound theory to work with and the best data that you can gather to operationalize the theory.</p>
<p>Assumption 10 requires that there be no perfect Multicollinearity. This assumption comes into play when we go beyond a single <span class="math inline">\(x\)</span> variable to using multiple independent variables in a model such as <span class="math inline">\(y = a + b_1x_1 + b_2x_2 + \ldots + b_kx_k + e\)</span>. In such an instance, <code>multicollinearity</code> implies that one or more of the <span class="math inline">\(x\)</span> variables are highly correlated. This becomes a problem because you cannot calculate the impact of a unit increase in <span class="math inline">\(x_i\)</span> by holding <span class="math inline">\(x_j\)</span> constant if <span class="math inline">\(x_i\)</span> and <span class="math inline">\(x_j\)</span> are highly correlated! There will always be some correlation between pairs of variables; that is not an issue. What is an issue is <code>severe multicollinearity</code> because it can increase the variance of the coefficient estimates and make the estimates very sensitive to minor changes in the model. The result is unstable regression coefficients that may even switch signs, making it difficult to specify the correct model. A classic sign of severe multicollinearity is when a model generates a high <span class="math inline">\(R^2\)</span> but very few of the independent variables are statistically significant. One way to minimize severe multicollinearity is to retain only one of a pair of highly correlated variables, combine them into some index via <code>scaling techniques</code>, or then try to increase the sample size since correlations tend to weaken in strength (not necessarily in statistical significance) with large samples.</p>
<p>There are several tests one could carry out to check for violations of these assumptions, and should some violations be discovered, there exist a vast array of techniques to adjust the model as well. Covering these techniques is beyond the scope of this introductory text but is addressed in the next text in this series. In that text we also extend the regression modeling framework to situations where the dependent variable is limited in some ways as, for example, a binary variable <span class="math inline">\((yes/no)\)</span> or a count variable that measures the number of trips patients make in a year to the emergency room, the number of highway fatalities, and so on. We also cover regression techniques for panel data, and some interesting applications of regression discontinuity designs, propensity scores, mixed models, small area estimation techniques, sample selection models, and ordinal and multinomial models. For now, recognize the fact that two things are your best friend: (1) A good, substantive grasp of the factors that influence the dependent variable, and (2) access to a large random sample with accurate measurement of the independent and dependent variables. Without these bases covered, there is little value in fitting any sort of a statistical model.</p>
<hr />
</div>
</div>
<div id="practice-problems-9" class="section level2 hasAnchor" number="12.5">
<h2><span class="header-section-number">12.5</span> Practice Problems<a href="linreg.html#practice-problems-9" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Problem 1</strong></p>
<p>Open up <a href="https://www.fueleconomy.gov/feg/epadata/vehicles.csv.zip">EPA’s Fuel Economy data</a>. These data are the result of vehicle testing done at the Environmental Protection Agency’s National Vehicle and Fuel Emissions Laboratory in Ann Arbor, Michigan, and by vehicle manufacturers with oversight by EPA. Read the accompanying document <a href="https://www.fueleconomy.gov/feg/ws/index.shtml#fuelType1">available here</a> to understand how some attribute is being measured.</p>
<ul>
<li>fuelType1</li>
<li>charge120</li>
<li>cylinders</li>
<li>displ</li>
<li>drive</li>
<li>year</li>
<li>ghgScore</li>
<li>highway08</li>
<li>city08</li>
<li>model</li>
<li>trany</li>
<li>youSaveSpend</li>
</ul>
<p>The data span several years so make sure you filter the file to retain only 2018 records. Now answer the following questions:</p>
<ol style="list-style-type: lower-alpha">
<li>How are city miles per gallon (<strong>city08</strong>) correlated with highway miles per gallon (<strong>highway08</strong>)? Is the correlation significant?</li>
<li>Graph the relationship between these two variables.</li>
<li>As an intern at the EPA, your job is to determine if engine displacement (<strong>displ</strong>) has any impact on miles per gallon, and if it does, how much of an impact is it? Fit two regression models, one with city and the other with highway miles per gallon as the outcome of interest. Then, for each model,
<ol style="list-style-type: lower-roman">
<li>Report and interpret the slope, the <span class="math inline">\(\bar{R}^2\)</span> and the standard error of the prediction.</li>
<li>Generate predicted values of miles per gallon both for the city and for the highway when displ = 1.5 versus when displ = 4.</li>
<li>Based on the two regressions you estimated, does a unit increase in <strong>displ</strong> have a larger impact on city miles per gallon or on highway miles per gallon?</li>
</ol></li>
<li>Add the variable <strong>drive</strong> to both regression models. Now,
<ol style="list-style-type: lower-roman">
<li>Report and interpret the impact of this new variable on miles per gallon</li>
<li>Evaluate whether the model fit has improved in terms of the <span class="math inline">\(\bar{R}^2\)</span> and the standard error of the prediction</li>
<li>Does <strong>drive</strong> have a larger impact on miles per gallon in the city or on the highway? What drive axle type has the largest versus smallest impact on city versus highway?</li>
</ol></li>
</ol>
<p><strong>Problem 2</strong></p>
<p>The next set of questions revolve around the <a href="https://aniruhil.github.io/avsr/teaching/dataviz/BostonMarathon.csv">2016 Boston Marathon race results available here</a>. The data-set contains the following variables:</p>
<ul>
<li>Bib = the runner’s bib number</li>
<li>Name = the runner’s name</li>
<li>Age = the runner’s age (in years)</li>
<li>M/F = the runner’s gender (M = Male; F = Female)</li>
<li>City = the runner’s home city</li>
<li>State = the runner’s home state</li>
<li>Country = the runner’s home country</li>
<li>finishtime = the runner’s time (in seconds) to the finish line</li>
</ul>
<p>Can we predict a runner’s finishing time on the basis of his/her age and gender? In order to answer this question,</p>
<ol style="list-style-type: lower-alpha">
<li>Fit the appropriate regression model</li>
<li>Interpret the partial slopes, the <span class="math inline">\(\bar{R}^2\)</span> and the standard error of the prediction</li>
<li>Interpret the 95% confidence intervals around the partial slope of age</li>
<li>Draw a scatter-plot with the regression line superimposed along with the 95% confidence intervals</li>
<li>Based on your results, does it look like Age has a larger impact for a particular gender? Which one and what sort of an impact differential is there? (<em>Hint:</em> In order to answer this question you will need to suitably modify your regression model and review the results.)</li>
</ol>
<p><strong>Problem 3</strong></p>
<p>Download the 2017 County Health Rankings data <a href="https://aniruhil.github.io/avsr/teaching/dataviz/CountyHealthRankings2017.sav">SPSS format from here</a>, <a href="https://aniruhil.github.io/avsr/teaching/dataviz/CountyHealthRankings2017.xlsx">Excel format from here</a> and the <a href="http://www.countyhealthrankings.org/sites/default/files/2017TrendsDocumentation.pdf">accompanying codebook</a>. You should see the following measures (<code>measurename</code>)</p>
<ol style="list-style-type: lower-roman">
<li>Adult obesity</li>
<li>Children in poverty</li>
<li>High school graduation</li>
<li>Preventable hospital stays</li>
<li>Unemployment rate</li>
</ol>
<p>Test for a pairwise correlation between all of these variables and note which ones are significant. Identify the pairs of variables that seem to be most strongly versus most weakly correlated with each other.</p>
<p><strong>Problem 4</strong></p>
<p>The <a href="https://aniruhil.github.io/avsr/teaching/dataviz/Mrozdata.xlsx">data for this analysis</a> come from the University of Michigan Panel Study of Income Dynamics (hereafter PSID) for the year 1975 (interview year 1976). Although this year was atypical of most of the 1970’s, only in 1976 did PSID directly interview the wives in the households. During all other years the head of the household’s interview supplied information about the wife’s labor market experiences during the previous year. One suspects that the own reporting is more accurate, and it is for this reason that many recent studies of married women’s labor supply have used these data.</p>
<p>This sample consists of 753 married white women between the ages of 30 and 60 in 1975, with 428 working at some time during the year. This sample size is smaller than most used in the studies reported in Table I. The dependent variable is <em>hours</em> = the wife’s annual hours of work in 1975, and measured as the product of the number of weeks the wife worked for money in 1975 and the average number of hours of work per week during the weeks she worked. The measure of the wage rate is the average hourly earnings, defined by dividing the total labor income of the wife in 1975 by the above measure of her hours of work.</p>
<ul>
<li>inlf = labor force participation in 1975 = 1</li>
<li>hours = wife’s hours of work in 1975</li>
<li>kidslt6 = number of children less than 6 years old in household</li>
<li>kidsge6 = number of children between ages 6 and 18 in household</li>
<li>age = wife’s age</li>
<li>educ = wife’s educational attainment, in years</li>
<li>wage = wife’s average hourly earnings, in 1975 dollars</li>
<li>repwage = wife’s wage reported at the time of the 1976 interview (not= 1975 estimated wage)</li>
<li>hushrs = husband’s hours worked in 1975</li>
<li>husage = husband’s age</li>
<li>huseduc = husband’s educational attainment, in years</li>
<li>huswage = husband’s wage, in 1975 dollars</li>
<li>faminc = family income, in 1975 dollars</li>
<li>mtr = Federal marginal tax rate facing women</li>
<li>mothereduc = wife’s mother’s educational attainment, in years</li>
<li>fathereduc = wife’s father’s educational attainment, in years</li>
<li>unemprate = unemployment rate in county of residence, in percentage points</li>
<li>city = lives in large city (SMSA) = 1</li>
<li>exper = actual years of wife’s previous labor market experience</li>
<li>nwifeinc = <span class="math inline">\(faminc - (wage \times hours)\)</span> in thousand dollars</li>
<li>lwage = log(wage)</li>
<li>expersq = <span class="math inline">\(exper^2\)</span></li>
</ul>
<p>The dependent variable of interest is <strong>wage</strong>, the wife’s average hourly earnings. Bearing this in mind,</p>
<ol style="list-style-type: lower-alpha">
<li>Fit a regression model with the wife’s educational attainment as the independent variable. Interpret the partial slopes, as appropriate, and the fit of the model.</li>
<li>Now fit a regression model with the wife’s age, educational attainment, hours worked, and whether the household is in a large city or not.</li>
<li>Interpret the partial slopes, as appropriate, and the fit of the model.</li>
<li>Does adding the husband’s wage to the model improve the fit? Explain with reference to appropriate estimates from the revised model.</li>
</ol>
<p><strong>Problem 5</strong></p>
<p>“The Student/Teacher Achievement Ratio (STAR) was a four-year longitudinal class-size study funded by the Tennessee General Assembly and conducted by the State Department of Education. Over 7,000 students in 79 schools were randomly assigned into one of three interventions: small class (13 to 17 students per teacher), regular class (22 to 25 students per teacher), and regular-with-aide class (22 to 25 students with a full-time teacher’s aide). Classroom teachers were also randomly assigned to the classes they would teach. The interventions were initiated as the students entered school in kindergarten and continued through third grade. The Project STAR public access data set contains data on test scores, treatment groups, and student and teacher characteristics for the four years of the experiment, from academic year 1985–1986 to academic year 1988–1989. The test score data analyzed in this chapter are the sum of the scores on the math and reading portion of the Stanford Achievement Test.” <a href="https://www.rdocumentation.org/packages/AER/versions/1.2-5/topics/STAR">Source</a> These <a href="https://aniruhil.github.io/avsr/teaching/dataviz/STARfull.xlsx">data can be downloaded from here</a>. Note the key variables as defined below:</p>
<ul>
<li>gender = student’s gender</li>
<li>ethnicity = student’s ethnicity</li>
<li>stark, star1, star2, star3 = whether the student was in a small classroom, a regular classroom, or a regular classroom with a teaching aide</li>
<li>readk, read1, read2, read3 = reading test scores in kindergarten/grade 1/grade 2/grade 3</li>
<li>mathk, math1, math2, math3 = mathematics test scores in kindergarten/grade 1/grade 2/grade 3</li>
<li>lunchk, lunch1, lunch2, lunch3 = student eligible for free/reduced lunch in kindergarten/grade 1/grade 2/grade 3</li>
<li>schoolk, school1, school2, school3 = school type student attended in kindergarten/grade 1/grade 2/grade 3</li>
<li>degreek, degree1, degree2, degree3 = teacher’s highest degree earned in kindergarten/grade 1/grade 2/grade 3</li>
<li>ladderk, ladder1, ladder2, ladder3 = teacher’s career ladder status in kindergarten/grade 1/grade 2/grade 3</li>
<li>experiencek, experience1, experience2, experience3 = teacher’s years of teaching experience in kindergarten/grade 1/grade 2/grade 3</li>
<li>tethnicityk, tethnicity1, tethnicity2, tethnicity3 = teacher’s ethnicity in kindergarten/grade 1/grade 2/grade 3</li>
</ul>
<ol style="list-style-type: lower-alpha">
<li>Fit a regression model to predict a student’s third-grade reading score on the basis of his/her kindergarten score. Interpret the <span class="math inline">\(\bar{R}^2\)</span> and the standard error of the prediction, as well as the slope.</li>
<li>Fit a regression model to predict a student’s third-grade reading score on the basis of his/her kindergarten score, gender, ethnicity, and the type of classroom he/she was in during the third-grade.</li>
<li>Interpret, where appropriate, partial slopes</li>
<li>Interpret the <span class="math inline">\(\bar{R}^2\)</span> and the standard error of the prediction</li>
<li>Does adding information on the third-grade teacher’s years of experience improve the model fit? Explain.</li>
<li>What if you also added whether the student was eligible for free/reduced lunch? Does the fit improve? What, if anything, changes in the partial slopes?</li>
</ol>
<p><strong>Problem 6</strong></p>
<p>The Ohio Department of Education gathers and releases a wealth of data on public schools and community schools; see, for instance, <a href="http://reportcard.education.ohio.gov/Pages/Power-User-Reports.aspx">here</a> and <a href="http://reportcard.education.ohio.gov/Pages/Download-Data.aspx">here</a>. A snippet of these data are provided for you <a href="https://aniruhil.github.io/avsr/teaching/dataviz/df15.sav">in this SPSS format file</a>. An <a href="https://aniruhil.github.io/avsr/teaching/dataviz/df15.csv">Excel version of the same data are available here</a> Note that you have data for community schools and public school districts; private and parochial schools are excluded.</p>
<ol style="list-style-type: lower-alpha">
<li>Check for correlations between the <strong>piscore</strong> (a measure used in the state’s accountability system with a higher score indicative of better performance), <strong>pctdisabled</strong> (percent of students attending the school who have a learning disability), <strong>pctecon</strong> (the percent of students who are deemed to be economically disadvantaged via measuring how many are eligible for free/reduced lunch), <strong>pctlep</strong> (the percent of students who have limited English proficiency), and <strong>pctminority</strong> (percent of students that are non-White). Report which correlations are/are not significant and the strength of these correlations as well.</li>
<li>Construct scatter-plots for all correlations tested above in part (a)</li>
<li>How well can you predict a school’s <strong>piscore</strong>? In order to answer this question, start by relying on the other variables listed in part (a) and folding them into the model as independent variables. Interpret all appropriate results, including the adjusted <span class="math inline">\(R^2\)</span> and the standard error of the prediction.</li>
<li>Does the prediction improve if you add school size (i.e., <strong>enrollment</strong>)? Note and report what changes and how.</li>
<li>What about if you add information on whether a school is a Community school (i.e., a charter school) or the traditional Public school? Note and report what changes and how.</li>
<li>All else being the same, does the model suggest that the average charter school performs better or worse than the average traditional public school? Explain.</li>
</ol>
<p><strong>Problem 7</strong></p>
<p><a href="https://aniruhil.github.io/avsr/teaching/dataviz/autos.csv">These data</a> reflect 392 observations on the following 9 variables.</p>
<ul>
<li>mpg = miles per gallon</li>
<li>cylinders = Number of cylinders between 4 and 8</li>
<li>displacement = Engine displacement (cu. inches)</li>
<li>horsepower = Engine horsepower</li>
<li>weight = Vehicle weight (lbs.)</li>
<li>acceleration = Time to accelerate from 0 to 60 mph (sec.)</li>
<li>year = Model year</li>
<li>origin = Origin of car (1. American, 2. European, 3. Japanese)</li>
<li>name = Vehicle name</li>
</ul>
<p>Note that the original data contained 408 observations but 16 observations with missing values have been removed.</p>
<ol style="list-style-type: lower-alpha">
<li>Regress mpg on weight and interpret the slope, adjusted R-squared, and the standard error of the estimate.</li>
<li>Now estimate the following regression model:
<span class="math display">\[mpg = \alpha + \beta_1(cylinders) + \beta_2(acceleration) + \beta_3(weight) + \beta_4(origin) + \epsilon\]</span>
Be careful; some of the independent variables will have to be coded or even recoded given some problematic distributions and the fact that they are stored in the data-set as numeric but are in fact categorical variables.</li>
<li>Interpret partial slopes, where appropriate, as well as the model fit.</li>
<li>revise the previous model by adding an interaction between acceleration and manufacturing origin of the automobile. What estimates have changed and how? Has the fit improved or worsened? Interpret the interaction effects, if appropriate.</li>
<li>Visually represent the interaction effects, holding the number of cylinders at their modal value and weight at its median.</li>
<li>Use appropriate graphics to examine relationships between the variables you have in the regression model and see if anything seems to be amiss. For example, are distributions of weight, acceleration, mpg, and the number of cylinders roughly similar across manufacturing origin? Or do you see substantial differences?</li>
</ol>
<p><strong>Problem 8</strong></p>
<p><a href="https://aniruhil.github.io/avsr/teaching/dataviz/carseats.csv">These data</a> are simulated data containing sales of child car seats at 400 different stores. The variables include</p>
<ul>
<li>Sales = Unit sales (in thousands) at each location</li>
<li>CompPrice = Price charged by competitor at each location</li>
<li>Income = Community income level (in thousands of dollars)</li>
<li>Advertising = Local advertising budget for company at each location (in thousands of dollars)</li>
<li>Population = Population size in region (in thousands)</li>
<li>Price = Price company charges for car seats at each site</li>
<li>ShelveLoc = A factor with levels Bad, Good and Medium indicating the quality of the shelving loca- tion for the car seats at each site</li>
<li>Age = Average age of the local population</li>
<li>Education = Education level at each location</li>
<li>Urban = A factor with levels No and Yes to indicate whether the store is in an urban or rural location</li>
<li>US = A factor with levels No and Yes to indicate whether the store is in the US or not</li>
</ul>
<p>The outcome of interest is the number of car seats sold (<strong>Sales</strong>) and the task given to you, as the chief data analyst for one of the largest retailers in the country is to figure out what features seem to best predict sales. Demonstrate your ability by fitting appropriate regression models and presenting the model that appears to perform the best.</p>
<p><strong>Problem 9</strong></p>
<p><a href="https://aniruhil.github.io/avsr/teaching/dataviz/college.csv">These data</a> reflect statistics for a large number of US Colleges from the 1995 issue of US News and World Report. The variables include</p>
<ul>
<li>Apps Number of applications received</li>
<li>Private = A factor with levels No and Yes indicating private or public university Apps Number of applications received</li>
<li>Accept = Number of applications accepted</li>
<li>Enroll = Number of new students enrolled</li>
<li>Top10perc = Pct. new students from top 10% of H.S. class</li>
<li>Top25perc = Pct. new students from top 25% of H.S. class</li>
<li>F.Undergrad = Number of fulltime undergraduates</li>
<li>P.Undergrad = Number of parttime undergraduates</li>
<li>Outstate = Out-of-state tuition</li>
<li>Room.Board = Room and board costs</li>
<li>Books = Estimated book costs</li>
<li>Personal = Estimated personal spending</li>
<li>PhD = Pct. of faculty with Ph.D.’s</li>
<li>Terminal = Pct. of faculty with terminal degree</li>
<li>S.F.Ratio = Student/faculty ratio</li>
<li>perc.alumni = Pct. alumni who donate</li>
<li>Expend = Instructional expenditure per student</li>
<li>Grad.Rate = Graduation rate</li>
</ul>
<p>You work for the Admissions office at your undergraduate alma mater and believe that you can use these data to figure out how to increase the number of applications accepted (<strong>Accept</strong>) at your university/college.</p>
<ol style="list-style-type: lower-alpha">
<li>Start by visually exploring the data. Note down any instances where you see high correlations or strange distributions (for example, very skewed or even sparse), if any of these features vary by private versus public, and so on.</li>
<li>Fit and interpret the results from a regression model with <strong>Apps</strong> as the dependent variable and two independent variables – <strong>Private</strong> and <strong>Accept</strong>.</li>
<li>Now add <strong>Room.Board</strong>, <strong>Grad.Rate</strong> and <strong>perc.alumni</strong>. Reinterpret this updated model and evaluate if this model has improved our ability to predict <strong>Apps</strong>.</li>
<li>Remove any variable(s) that you thought, based on your work in (a), could be problematic given the usual assumptions that underlie regression analysis. Reinterpret the resulting model and compare with the previous models you fit to the data. Is your model performing better? Briefly explain your conclusion.</li>
</ol>
<p><strong>Problem 10</strong></p>
<p><a href="https://aniruhil.github.io/avsr/teaching/dataviz/credit.csv">These data</a> reflect a simulated data-set containing information on ten thousand customers. The aim here is to predict how much balance an individual is likely to carry on their credit card. The variables are:</p>
<ul>
<li>ID = Identification</li>
<li>Income = Income in $10,000’s</li>
<li>Limit = Credit limit</li>
<li>Rating = Credit rating</li>
<li>Cards = Number of credit cards</li>
<li>Age = Age in years</li>
<li>Education = Number of years of education</li>
<li>Gender = A factor with levels Male and Female</li>
<li>Student = A factor with levels No and Yes indicating whether the individual was a student</li>
<li>Married = A factor with levels No and Yes indicating whether the individual was married</li>
<li>Ethnicity = A factor with levels African American, Asian, and Caucasian indicating the individual’s ethnicity</li>
<li>Balance = Average credit card balance in dollars</li>
</ul>
<ol style="list-style-type: lower-alpha">
<li>Visually explore the variables in the data-set (excluding the <strong>ID</strong> variable) and briefly write-up what you see in the data. Note any distributions that are of special concern.</li>
<li>Now fit a regression model with <strong>Balance</strong> as the dependent variable and the following independent variables: <strong>Rating</strong>, <strong>Income</strong>, <strong>Gender</strong>, <strong>Student</strong>, __Married_ and <strong>Ethnicity</strong>. Interpret your results.</li>
<li>Now eliminate all independent variables that are not statistically significant at <span class="math inline">\(\alpha = 0.05\)</span> and look at your estimates. Has the model improved or worsened? In what ways, if any?</li>
</ol>
<p><strong>Problem 11</strong></p>
<p><a href="https://aniruhil.github.io/avsr/teaching/dataviz/wage.csv">These data</a> reflect wage and other data for a group of 3000 male workers in the Mid-Atlantic region.</p>
<ul>
<li>year = Year that wage information was recorded</li>
<li>age = Age of worker</li>
<li>maritl = A factor with levels 1. Never Married 2. Married 3. Widowed 4. Divorced and 5. Separated indicating marital status</li>
<li>race = A factor with levels 1. White 2. Black 3. Asian and 4. Other indicating race</li>
<li>education = A factor with levels 1. &lt; HS Grad 2. HS Grad 3. Some College 4. College Grad
and 5. Advanced Degree indicating education level</li>
<li>region = Region of the country (mid-Atlantic only)</li>
<li>jobclass = A factor with levels 1. Industrial and 2. Information indicating type of job</li>
<li>health = A factor with levels 1. &lt;=Good and 2. &gt;=Very Good indicating health level of worker</li>
<li>health_ins = A factor with levels 1. Yes and 2. No indicating whether worker has health insurance</li>
<li>logwage = Log of workers wage</li>
<li>wage = Workers raw wage</li>
</ul>
<ol style="list-style-type: lower-alpha">
<li>Subset the data-set to the year 2003 and fit the following regression model:</li>
</ol>
<p><span class="math display">\[wage = \alpha + \beta_1(education) + \beta_2(jobclass) + \beta_3(race) + \beta_4(age) + \epsilon\]</span>
(b) Interpret your regression results.
(c) Subset the data to 2009 and generate predicted values of wage with the 2003 regression estimates you generated in (a)
(d) Generate an interaction between <strong>age</strong> and <strong>education</strong> and refit the model you estimated in (a) to the 2003 data. Does the model fit improve or worsen? What estimates change and how?</p>
<p><strong>Problem 12</strong></p>
<p><a href="https://aniruhil.github.io/avsr/teaching/dataviz/Prestige.csv">These data</a> are from the 1971 Census of Canada and reflect the following variables:</p>
<ul>
<li>education = Average education of occupational incumbents, years, in 1971</li>
<li>income = Average income of incumbents, dollars, in 1971</li>
<li>women = Percentage of incumbents who are women</li>
<li>prestige = Pineo-Porter prestige score for occupation, from a social survey conducted in the mid-1960s</li>
<li>census = Canadian Census occupational code</li>
<li>type = Type of occupation. A factor with levels: bc, Blue Collar; prof, Professional, Managerial, and Technical; wc, White Collar</li>
</ul>
<p>The goal is to see if we can predict an occupation’s <strong>prestige</strong> on the basis of specific independent variables.</p>
<ol style="list-style-type: lower-alpha">
<li>Fit a simple regression model with a lone independent variable – <strong>type</strong> and interpret the estimates.</li>
<li>Now add <strong>women</strong> to the model and see how the estimates change, if at all</li>
<li>Now add <strong>income</strong> and <strong>education</strong> and interpret the new estimates</li>
<li>Check to see if <strong>income</strong> and <strong>education</strong> are highly correlated, as should be expected. If they are, and the correlation is significant, exclude one of these from the model fit in (c) and see how the results change. Has there been any significant reduction in predictive ability or a substantial rise in our average prediction error?</li>
</ol>
<p><strong>Problem 13</strong></p>
<p><a href="https://aniruhil.github.io/avsr/teaching/dataviz/kidiq.csv">Here are Andrew Gelman’s data</a>
on the IQ scores of some children and, for each child, information about their mother:</p>
<ul>
<li>kid_score = child’s IQ score</li>
<li>mom_hs = whether the mother has a high school degree (=1) or not (=0)</li>
<li>mom_iq = mother’s IQ score</li>
<li>mom_age = mother’s age, in years</li>
<li>mom_work = mother’s work history, coded as 1 = did not work in first three years of child’s life, 2 = worked in 2nd or 3rd year of child’s life; 3 = worked part-time in first year of child’s life, and; 4 = worked full-time in first year of child’s life</li>
</ul>
<ol style="list-style-type: lower-alpha">
<li>Fit a simple regression model of the child’s IQ score as a function of the mother’s IQ score and whether the mother has a high school degree (or not)</li>
<li>Is there a significant interaction between the mother’s IQ and whether the mother has a high school degree (or not)? Test in a regression setting and state your conclusion.</li>
<li>Can you improve the model by adding the mother’s work history? Be sure to test for possible interactions, as appropriate and defensible.</li>
</ol>
<p><strong>Problem 14</strong></p>
<p><a href="https://aniruhil.github.io/avsr/teaching/dataviz/intlturnout.csv">These data</a> come from the <a href="https://www.idea.int/data-tools">Institute for Democracy and Electoral Assistance (IDEA)</a> and contain country-level information on voter turnout. Read all about the variables in this particular database <a href="https://www.idea.int/data-tools/data/voter-turnout">here</a>. I have added other variables, including <strong>Income Group</strong> that slots each country into the <a href="https://goo.gl/YPsOTo">current World Bank classification system</a>. The data-set thus includes the following variables:</p>
<ul>
<li>Country = country name</li>
<li>Region = World region</li>
<li>Income group = World Bank classification</li>
<li>Year = Year turnout data refer to</li>
<li>Compulsory voting = whether voting is compusive or not, codes as “Yes” or “No”</li>
<li>turnout = Voter turnout (in percent)</li>
<li>vapturnout = Voting age population turnout (in percent)</li>
<li>popn = Population</li>
<li>vappopn = Voting age population</li>
<li>regdvoters = Number of registered voters</li>
<li>civilliberties = Freedom House’s rating on civil liberties (low = bad; high = good)</li>
<li>politicalrights = Freedom House’s rating on political rights (low = bad; high = good)</li>
</ul>
<ol style="list-style-type: lower-alpha">
<li>Fit a regression model with <strong>turnout</strong> as the dependent variable and <strong>popn</strong> as the independent variable. Interpret the results, including the model fit.</li>
<li>Now add whether voting is compulsory or not. How do the estimates change? How good is the model fit?</li>
<li>What if you add <strong>civilliberties</strong> and <strong>politicalrights</strong>? How do the results and the model fit change?</li>
<li>Add yet another variable, <strong>Income group</strong>. How do the results and the model fit change?</li>
<li>Given all the models you have fit, which model has the best overall fit? Focus on <span class="math inline">\(\bar{R}^2\)</span> and on the average prediction error.</li>
</ol>

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-107619033-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-107619033-1');
</script>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="props.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="summation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "serif",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "section",
    "css": "toc.css"
  },
  "theme": "sandstone"
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
